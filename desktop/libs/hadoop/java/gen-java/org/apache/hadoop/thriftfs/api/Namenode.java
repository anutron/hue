/**
 * Autogenerated by Thrift
 *
 * DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
 */
package org.apache.hadoop.thriftfs.api;

import java.util.List;
import java.util.ArrayList;
import java.util.Map;
import java.util.HashMap;
import java.util.EnumMap;
import java.util.Set;
import java.util.HashSet;
import java.util.EnumSet;
import java.util.Collections;
import java.util.BitSet;
import java.util.Arrays;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import org.apache.thrift.*;
import org.apache.thrift.meta_data.*;
import org.apache.thrift.protocol.*;

public class Namenode {

  /**
   * Provides an interface to a Hadoop Namenode. It is basically a Thrift
   * translation of org.apache.hadoop.hdfs.protocol.ClientProtocol.
   */
  public interface Iface extends org.apache.hadoop.thriftfs.api.HadoopServiceBase.Iface {

    /**
     * Set permissions of an existing file or directory.
     * 
     * @param ctx
     * @param path Path of the file or directory.
     * 
     * @param perms New permissions for the file or directory.
     */
    public void chmod(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short perms) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Set owner of a file or directory.
     * 
     * If either parameter 'owner' or 'group' is set to null, that
     * parameter is left unchanged.
     * 
     * Parameters 'owner' and 'group' cannot be both null.
     * 
     * @param ctx
     * @param path Path to the file or directory
     * 
     * @param owner New owner.
     * 
     * @param group New group.
     */
    public void chown(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, String owner, String group) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Return a list containing:
     *   (index 0) The total storage capacity of the file system (in bytes).
     *   (index 1) The total used space of the file system (in bytes).
     *   (index 2) The available storage of the file system (in bytes).
     * 
     * @param ctx
     */
    public List<Long> df(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Enter safe mode.
     * 
     * @param ctx
     */
    public void enterSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get a list of all blocks containing a region of a file
     * 
     * @param ctx
     * @param path Path to the file.
     * 
     * @param offset Offset of the region.
     * 
     * @param length Length of the region
     */
    public List<Block> getBlocks(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long offset, long length) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get a report on the system's current data nodes.
     * Note that ctx is currently ignored by the server.
     * 
     * @param ctx
     * @param type Type of data nodes to return
     * information about.
     */
    public List<DatanodeInfo> getDatanodeReport(org.apache.hadoop.thriftfs.api.RequestContext ctx, DatanodeReportType type) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get a health report of DFS.  Note that ctx is ignored by the server.
     * 
     * @param ctx
     */
    public DFSHealthReport getHealthReport(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get the preferred block size for the given file.
     * 
     * The path must exist, or common.IOException is thrown.
     * 
     * @param ctx
     * @param path Path to the file.
     */
    public long getPreferredBlockSize(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Returns whether HDFS is in safe mode or not.
     * 
     * @param ctx
     */
    public boolean isInSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Leave safe mode.
     * 
     * @param ctx
     */
    public void leaveSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get a listing of the indicated directory.
     * 
     * @param ctx
     * @param path Path to the directory.
     */
    public List<Stat> ls(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Create a directory (or hierarchy of directories).
     * 
     * Returns false if directory did not exist and could not be created,
     * true otherwise.
     * 
     * @param ctx
     * @param path Path to the directory.
     * 
     * @param perms Access permissions of the directory.
     */
    public boolean mkdirhier(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short perms) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Tells the name node to reread the hosts and exclude files.
     * 
     * @param ctx
     */
    public void refreshNodes(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Rename an item in the file system namespace.
     * 
     * Returns true  if successful, or
     *         false if the old name does not exist or if the new name already
     *               belongs to the namespace.
     * 
     * @param ctx
     * @param path Path to existing file or directory.
     * 
     * @param newPath New path.
     */
    public boolean rename(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, String newPath) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Report corrupted blocks.
     * 
     * @param ctx
     * @param blocks List of corrupted blocks.
     */
    public void reportBadBlocks(org.apache.hadoop.thriftfs.api.RequestContext ctx, List<Block> blocks) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get information about a path in HDFS.
     * 
     * Return value will be nul if path does not exist.
     * 
     * @param ctx
     * @param path Path of the file or directory.
     */
    public Stat stat(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get the summary of a directory's contents.
     * 
     * Note that this has runtime linear in the total number of nodes
     * in the directory tree - this can be expensive for directories
     * near the top of a big HDFS. Use with care.
     * 
     * @param ctx
     * @param Path
     */
    public ContentSummary getContentSummary(org.apache.hadoop.thriftfs.api.RequestContext ctx, String Path) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Get ContentSummary objects for multiple directories simultaneously. The same warnings
     * apply as for getContentSummary(...) above.
     * 
     * @param ctx
     * @param paths
     */
    public List<ContentSummary> multiGetContentSummary(org.apache.hadoop.thriftfs.api.RequestContext ctx, List<String> paths) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Set the quota for a directory.
     * 
     * Quota parameters may have three types of values:
     * 
     *    (1) 0 or more:      Quota will be set to that value.
     *    (2) QUOTA_DONT_SET: Quota will not be changed,
     *    (3) QUOTA_RESET:    Quota will be reset.
     * 
     * Any other value is a runtime error.
     * 
     * @param ctx
     * @param path Path of the directory.
     * 
     * @param namespaceQuota Limit on the number of names in the directory.
     * 
     * @param diskspaceQuota Limit on disk space occupied by all the files in the
     * directory.
     */
    public void setQuota(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long namespaceQuota, long diskspaceQuota) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Set replication factor for an existing file.
     * 
     * This call just updates the value of the replication factor. The actual
     * block replication is not expected to be performed during this method call.
     * The blocks will be populated or removed in the background as the result of
     * the routine block maintenance procedures.
     * 
     * Returns true if successful, false if file does not exist or is a
     * directory.
     * 
     * @param ctx
     * @param path Path of the file.
     * 
     * @param replication New replication factor.
     */
    public boolean setReplication(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short replication) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Delete a file or directory from the file system.
     * 
     * Any blocks belonging to the deleted files will be garbage-collected.
     * 
     * @param ctx
     * @param path Path of the file or directory.
     * 
     * @param recursive Delete a non-empty directory recursively.
     */
    public boolean unlink(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, boolean recursive) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Sets the modification and access time of a file or directory.
     * 
     * Setting *one single time paramater* to -1 means that time parameter
     * must not be set by this call.
     * 
     * Setting *both time parameters* to -1 means both of them must be set to
     * the current time.
     * 
     * @param ctx
     * @param path Path of the file or directory.
     * 
     * @param atime Access time in milliseconds since 1970-01-01 00:00 UTC
     * 
     * @param mtime Modification time in milliseconds since 1970-01-01 00:00 UTC
     */
    public void utime(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long atime, long mtime) throws org.apache.hadoop.thriftfs.api.IOException, TException;

    /**
     * Inform the namenode that a datanode process has started.
     * 
     * @param name <host name>:<port number> of the datanode
     * 
     * @param storage the storage id of the datanode
     * 
     * @param thriftPort Thrift port of the datanode
     */
    public void datanodeUp(String name, String storage, int thriftPort) throws TException;

    /**
     * Inform the namenode that a datanode process has stopped.
     * 
     * @param name <host name>:<port number> of the datanode
     * 
     * @param storage the storage id of the datanode
     * 
     * @param thriftPort Thrift port of the datanode
     */
    public void datanodeDown(String name, String storage, int thriftPort) throws TException;

  }

  public static class Client extends org.apache.hadoop.thriftfs.api.HadoopServiceBase.Client implements Iface {
    public Client(TProtocol prot)
    {
      this(prot, prot);
    }

    public Client(TProtocol iprot, TProtocol oprot)
    {
      super(iprot, oprot);
    }

    public void chmod(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short perms) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_chmod(ctx, path, perms);
      recv_chmod();
    }

    public void send_chmod(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short perms) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("chmod", TMessageType.CALL, seqid_));
      chmod_args args = new chmod_args();
      args.ctx = ctx;
      args.path = path;
      args.perms = perms;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_chmod() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      chmod_result result = new chmod_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public void chown(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, String owner, String group) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_chown(ctx, path, owner, group);
      recv_chown();
    }

    public void send_chown(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, String owner, String group) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("chown", TMessageType.CALL, seqid_));
      chown_args args = new chown_args();
      args.ctx = ctx;
      args.path = path;
      args.owner = owner;
      args.group = group;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_chown() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      chown_result result = new chown_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public List<Long> df(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_df(ctx);
      return recv_df();
    }

    public void send_df(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("df", TMessageType.CALL, seqid_));
      df_args args = new df_args();
      args.ctx = ctx;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public List<Long> recv_df() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      df_result result = new df_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "df failed: unknown result");
    }

    public void enterSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_enterSafeMode(ctx);
      recv_enterSafeMode();
    }

    public void send_enterSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("enterSafeMode", TMessageType.CALL, seqid_));
      enterSafeMode_args args = new enterSafeMode_args();
      args.ctx = ctx;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_enterSafeMode() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      enterSafeMode_result result = new enterSafeMode_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public List<Block> getBlocks(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long offset, long length) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_getBlocks(ctx, path, offset, length);
      return recv_getBlocks();
    }

    public void send_getBlocks(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long offset, long length) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("getBlocks", TMessageType.CALL, seqid_));
      getBlocks_args args = new getBlocks_args();
      args.ctx = ctx;
      args.path = path;
      args.offset = offset;
      args.length = length;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public List<Block> recv_getBlocks() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      getBlocks_result result = new getBlocks_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "getBlocks failed: unknown result");
    }

    public List<DatanodeInfo> getDatanodeReport(org.apache.hadoop.thriftfs.api.RequestContext ctx, DatanodeReportType type) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_getDatanodeReport(ctx, type);
      return recv_getDatanodeReport();
    }

    public void send_getDatanodeReport(org.apache.hadoop.thriftfs.api.RequestContext ctx, DatanodeReportType type) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("getDatanodeReport", TMessageType.CALL, seqid_));
      getDatanodeReport_args args = new getDatanodeReport_args();
      args.ctx = ctx;
      args.type = type;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public List<DatanodeInfo> recv_getDatanodeReport() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      getDatanodeReport_result result = new getDatanodeReport_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "getDatanodeReport failed: unknown result");
    }

    public DFSHealthReport getHealthReport(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_getHealthReport(ctx);
      return recv_getHealthReport();
    }

    public void send_getHealthReport(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("getHealthReport", TMessageType.CALL, seqid_));
      getHealthReport_args args = new getHealthReport_args();
      args.ctx = ctx;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public DFSHealthReport recv_getHealthReport() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      getHealthReport_result result = new getHealthReport_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "getHealthReport failed: unknown result");
    }

    public long getPreferredBlockSize(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_getPreferredBlockSize(ctx, path);
      return recv_getPreferredBlockSize();
    }

    public void send_getPreferredBlockSize(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("getPreferredBlockSize", TMessageType.CALL, seqid_));
      getPreferredBlockSize_args args = new getPreferredBlockSize_args();
      args.ctx = ctx;
      args.path = path;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public long recv_getPreferredBlockSize() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      getPreferredBlockSize_result result = new getPreferredBlockSize_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "getPreferredBlockSize failed: unknown result");
    }

    public boolean isInSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_isInSafeMode(ctx);
      return recv_isInSafeMode();
    }

    public void send_isInSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("isInSafeMode", TMessageType.CALL, seqid_));
      isInSafeMode_args args = new isInSafeMode_args();
      args.ctx = ctx;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public boolean recv_isInSafeMode() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      isInSafeMode_result result = new isInSafeMode_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "isInSafeMode failed: unknown result");
    }

    public void leaveSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_leaveSafeMode(ctx);
      recv_leaveSafeMode();
    }

    public void send_leaveSafeMode(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("leaveSafeMode", TMessageType.CALL, seqid_));
      leaveSafeMode_args args = new leaveSafeMode_args();
      args.ctx = ctx;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_leaveSafeMode() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      leaveSafeMode_result result = new leaveSafeMode_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public List<Stat> ls(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_ls(ctx, path);
      return recv_ls();
    }

    public void send_ls(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("ls", TMessageType.CALL, seqid_));
      ls_args args = new ls_args();
      args.ctx = ctx;
      args.path = path;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public List<Stat> recv_ls() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      ls_result result = new ls_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "ls failed: unknown result");
    }

    public boolean mkdirhier(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short perms) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_mkdirhier(ctx, path, perms);
      return recv_mkdirhier();
    }

    public void send_mkdirhier(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short perms) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("mkdirhier", TMessageType.CALL, seqid_));
      mkdirhier_args args = new mkdirhier_args();
      args.ctx = ctx;
      args.path = path;
      args.perms = perms;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public boolean recv_mkdirhier() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      mkdirhier_result result = new mkdirhier_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "mkdirhier failed: unknown result");
    }

    public void refreshNodes(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_refreshNodes(ctx);
      recv_refreshNodes();
    }

    public void send_refreshNodes(org.apache.hadoop.thriftfs.api.RequestContext ctx) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("refreshNodes", TMessageType.CALL, seqid_));
      refreshNodes_args args = new refreshNodes_args();
      args.ctx = ctx;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_refreshNodes() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      refreshNodes_result result = new refreshNodes_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public boolean rename(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, String newPath) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_rename(ctx, path, newPath);
      return recv_rename();
    }

    public void send_rename(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, String newPath) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("rename", TMessageType.CALL, seqid_));
      rename_args args = new rename_args();
      args.ctx = ctx;
      args.path = path;
      args.newPath = newPath;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public boolean recv_rename() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      rename_result result = new rename_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "rename failed: unknown result");
    }

    public void reportBadBlocks(org.apache.hadoop.thriftfs.api.RequestContext ctx, List<Block> blocks) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_reportBadBlocks(ctx, blocks);
      recv_reportBadBlocks();
    }

    public void send_reportBadBlocks(org.apache.hadoop.thriftfs.api.RequestContext ctx, List<Block> blocks) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("reportBadBlocks", TMessageType.CALL, seqid_));
      reportBadBlocks_args args = new reportBadBlocks_args();
      args.ctx = ctx;
      args.blocks = blocks;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_reportBadBlocks() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      reportBadBlocks_result result = new reportBadBlocks_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public Stat stat(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_stat(ctx, path);
      return recv_stat();
    }

    public void send_stat(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("stat", TMessageType.CALL, seqid_));
      stat_args args = new stat_args();
      args.ctx = ctx;
      args.path = path;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public Stat recv_stat() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      stat_result result = new stat_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "stat failed: unknown result");
    }

    public ContentSummary getContentSummary(org.apache.hadoop.thriftfs.api.RequestContext ctx, String Path) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_getContentSummary(ctx, Path);
      return recv_getContentSummary();
    }

    public void send_getContentSummary(org.apache.hadoop.thriftfs.api.RequestContext ctx, String Path) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("getContentSummary", TMessageType.CALL, seqid_));
      getContentSummary_args args = new getContentSummary_args();
      args.ctx = ctx;
      args.Path = Path;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public ContentSummary recv_getContentSummary() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      getContentSummary_result result = new getContentSummary_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "getContentSummary failed: unknown result");
    }

    public List<ContentSummary> multiGetContentSummary(org.apache.hadoop.thriftfs.api.RequestContext ctx, List<String> paths) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_multiGetContentSummary(ctx, paths);
      return recv_multiGetContentSummary();
    }

    public void send_multiGetContentSummary(org.apache.hadoop.thriftfs.api.RequestContext ctx, List<String> paths) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("multiGetContentSummary", TMessageType.CALL, seqid_));
      multiGetContentSummary_args args = new multiGetContentSummary_args();
      args.ctx = ctx;
      args.paths = paths;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public List<ContentSummary> recv_multiGetContentSummary() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      multiGetContentSummary_result result = new multiGetContentSummary_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "multiGetContentSummary failed: unknown result");
    }

    public void setQuota(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long namespaceQuota, long diskspaceQuota) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_setQuota(ctx, path, namespaceQuota, diskspaceQuota);
      recv_setQuota();
    }

    public void send_setQuota(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long namespaceQuota, long diskspaceQuota) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("setQuota", TMessageType.CALL, seqid_));
      setQuota_args args = new setQuota_args();
      args.ctx = ctx;
      args.path = path;
      args.namespaceQuota = namespaceQuota;
      args.diskspaceQuota = diskspaceQuota;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_setQuota() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      setQuota_result result = new setQuota_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public boolean setReplication(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short replication) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_setReplication(ctx, path, replication);
      return recv_setReplication();
    }

    public void send_setReplication(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, short replication) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("setReplication", TMessageType.CALL, seqid_));
      setReplication_args args = new setReplication_args();
      args.ctx = ctx;
      args.path = path;
      args.replication = replication;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public boolean recv_setReplication() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      setReplication_result result = new setReplication_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "setReplication failed: unknown result");
    }

    public boolean unlink(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, boolean recursive) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_unlink(ctx, path, recursive);
      return recv_unlink();
    }

    public void send_unlink(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, boolean recursive) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("unlink", TMessageType.CALL, seqid_));
      unlink_args args = new unlink_args();
      args.ctx = ctx;
      args.path = path;
      args.recursive = recursive;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public boolean recv_unlink() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      unlink_result result = new unlink_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.isSetSuccess()) {
        return result.success;
      }
      if (result.err != null) {
        throw result.err;
      }
      throw new TApplicationException(TApplicationException.MISSING_RESULT, "unlink failed: unknown result");
    }

    public void utime(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long atime, long mtime) throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      send_utime(ctx, path, atime, mtime);
      recv_utime();
    }

    public void send_utime(org.apache.hadoop.thriftfs.api.RequestContext ctx, String path, long atime, long mtime) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("utime", TMessageType.CALL, seqid_));
      utime_args args = new utime_args();
      args.ctx = ctx;
      args.path = path;
      args.atime = atime;
      args.mtime = mtime;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_utime() throws org.apache.hadoop.thriftfs.api.IOException, TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      utime_result result = new utime_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      if (result.err != null) {
        throw result.err;
      }
      return;
    }

    public void datanodeUp(String name, String storage, int thriftPort) throws TException
    {
      send_datanodeUp(name, storage, thriftPort);
      recv_datanodeUp();
    }

    public void send_datanodeUp(String name, String storage, int thriftPort) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("datanodeUp", TMessageType.CALL, seqid_));
      datanodeUp_args args = new datanodeUp_args();
      args.name = name;
      args.storage = storage;
      args.thriftPort = thriftPort;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_datanodeUp() throws TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      datanodeUp_result result = new datanodeUp_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      return;
    }

    public void datanodeDown(String name, String storage, int thriftPort) throws TException
    {
      send_datanodeDown(name, storage, thriftPort);
      recv_datanodeDown();
    }

    public void send_datanodeDown(String name, String storage, int thriftPort) throws TException
    {
      oprot_.writeMessageBegin(new TMessage("datanodeDown", TMessageType.CALL, seqid_));
      datanodeDown_args args = new datanodeDown_args();
      args.name = name;
      args.storage = storage;
      args.thriftPort = thriftPort;
      args.write(oprot_);
      oprot_.writeMessageEnd();
      oprot_.getTransport().flush();
    }

    public void recv_datanodeDown() throws TException
    {
      TMessage msg = iprot_.readMessageBegin();
      if (msg.type == TMessageType.EXCEPTION) {
        TApplicationException x = TApplicationException.read(iprot_);
        iprot_.readMessageEnd();
        throw x;
      }
      datanodeDown_result result = new datanodeDown_result();
      result.read(iprot_);
      iprot_.readMessageEnd();
      return;
    }

  }
  public static class Processor extends org.apache.hadoop.thriftfs.api.HadoopServiceBase.Processor implements TProcessor {
    private static final Logger LOGGER = LoggerFactory.getLogger(Processor.class.getName());
    public Processor(Iface iface)
    {
      super(iface);
      iface_ = iface;
      processMap_.put("chmod", new chmod());
      processMap_.put("chown", new chown());
      processMap_.put("df", new df());
      processMap_.put("enterSafeMode", new enterSafeMode());
      processMap_.put("getBlocks", new getBlocks());
      processMap_.put("getDatanodeReport", new getDatanodeReport());
      processMap_.put("getHealthReport", new getHealthReport());
      processMap_.put("getPreferredBlockSize", new getPreferredBlockSize());
      processMap_.put("isInSafeMode", new isInSafeMode());
      processMap_.put("leaveSafeMode", new leaveSafeMode());
      processMap_.put("ls", new ls());
      processMap_.put("mkdirhier", new mkdirhier());
      processMap_.put("refreshNodes", new refreshNodes());
      processMap_.put("rename", new rename());
      processMap_.put("reportBadBlocks", new reportBadBlocks());
      processMap_.put("stat", new stat());
      processMap_.put("getContentSummary", new getContentSummary());
      processMap_.put("multiGetContentSummary", new multiGetContentSummary());
      processMap_.put("setQuota", new setQuota());
      processMap_.put("setReplication", new setReplication());
      processMap_.put("unlink", new unlink());
      processMap_.put("utime", new utime());
      processMap_.put("datanodeUp", new datanodeUp());
      processMap_.put("datanodeDown", new datanodeDown());
    }

    private Iface iface_;

    public boolean process(TProtocol iprot, TProtocol oprot) throws TException
    {
      TMessage msg = iprot.readMessageBegin();
      ProcessFunction fn = processMap_.get(msg.name);
      if (fn == null) {
        TProtocolUtil.skip(iprot, TType.STRUCT);
        iprot.readMessageEnd();
        TApplicationException x = new TApplicationException(TApplicationException.UNKNOWN_METHOD, "Invalid method name: '"+msg.name+"'");
        oprot.writeMessageBegin(new TMessage(msg.name, TMessageType.EXCEPTION, msg.seqid));
        x.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
        return true;
      }
      fn.process(msg.seqid, iprot, oprot);
      return true;
    }

    private class chmod implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        chmod_args args = new chmod_args();
        args.read(iprot);
        iprot.readMessageEnd();
        chmod_result result = new chmod_result();
        try {
          iface_.chmod(args.ctx, args.path, args.perms);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing chmod", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing chmod");
          oprot.writeMessageBegin(new TMessage("chmod", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("chmod", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class chown implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        chown_args args = new chown_args();
        args.read(iprot);
        iprot.readMessageEnd();
        chown_result result = new chown_result();
        try {
          iface_.chown(args.ctx, args.path, args.owner, args.group);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing chown", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing chown");
          oprot.writeMessageBegin(new TMessage("chown", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("chown", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class df implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        df_args args = new df_args();
        args.read(iprot);
        iprot.readMessageEnd();
        df_result result = new df_result();
        try {
          result.success = iface_.df(args.ctx);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing df", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing df");
          oprot.writeMessageBegin(new TMessage("df", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("df", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class enterSafeMode implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        enterSafeMode_args args = new enterSafeMode_args();
        args.read(iprot);
        iprot.readMessageEnd();
        enterSafeMode_result result = new enterSafeMode_result();
        try {
          iface_.enterSafeMode(args.ctx);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing enterSafeMode", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing enterSafeMode");
          oprot.writeMessageBegin(new TMessage("enterSafeMode", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("enterSafeMode", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class getBlocks implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        getBlocks_args args = new getBlocks_args();
        args.read(iprot);
        iprot.readMessageEnd();
        getBlocks_result result = new getBlocks_result();
        try {
          result.success = iface_.getBlocks(args.ctx, args.path, args.offset, args.length);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing getBlocks", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing getBlocks");
          oprot.writeMessageBegin(new TMessage("getBlocks", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("getBlocks", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class getDatanodeReport implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        getDatanodeReport_args args = new getDatanodeReport_args();
        args.read(iprot);
        iprot.readMessageEnd();
        getDatanodeReport_result result = new getDatanodeReport_result();
        try {
          result.success = iface_.getDatanodeReport(args.ctx, args.type);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing getDatanodeReport", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing getDatanodeReport");
          oprot.writeMessageBegin(new TMessage("getDatanodeReport", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("getDatanodeReport", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class getHealthReport implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        getHealthReport_args args = new getHealthReport_args();
        args.read(iprot);
        iprot.readMessageEnd();
        getHealthReport_result result = new getHealthReport_result();
        try {
          result.success = iface_.getHealthReport(args.ctx);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing getHealthReport", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing getHealthReport");
          oprot.writeMessageBegin(new TMessage("getHealthReport", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("getHealthReport", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class getPreferredBlockSize implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        getPreferredBlockSize_args args = new getPreferredBlockSize_args();
        args.read(iprot);
        iprot.readMessageEnd();
        getPreferredBlockSize_result result = new getPreferredBlockSize_result();
        try {
          result.success = iface_.getPreferredBlockSize(args.ctx, args.path);
          result.setSuccessIsSet(true);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing getPreferredBlockSize", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing getPreferredBlockSize");
          oprot.writeMessageBegin(new TMessage("getPreferredBlockSize", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("getPreferredBlockSize", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class isInSafeMode implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        isInSafeMode_args args = new isInSafeMode_args();
        args.read(iprot);
        iprot.readMessageEnd();
        isInSafeMode_result result = new isInSafeMode_result();
        try {
          result.success = iface_.isInSafeMode(args.ctx);
          result.setSuccessIsSet(true);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing isInSafeMode", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing isInSafeMode");
          oprot.writeMessageBegin(new TMessage("isInSafeMode", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("isInSafeMode", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class leaveSafeMode implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        leaveSafeMode_args args = new leaveSafeMode_args();
        args.read(iprot);
        iprot.readMessageEnd();
        leaveSafeMode_result result = new leaveSafeMode_result();
        try {
          iface_.leaveSafeMode(args.ctx);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing leaveSafeMode", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing leaveSafeMode");
          oprot.writeMessageBegin(new TMessage("leaveSafeMode", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("leaveSafeMode", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class ls implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        ls_args args = new ls_args();
        args.read(iprot);
        iprot.readMessageEnd();
        ls_result result = new ls_result();
        try {
          result.success = iface_.ls(args.ctx, args.path);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing ls", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing ls");
          oprot.writeMessageBegin(new TMessage("ls", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("ls", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class mkdirhier implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        mkdirhier_args args = new mkdirhier_args();
        args.read(iprot);
        iprot.readMessageEnd();
        mkdirhier_result result = new mkdirhier_result();
        try {
          result.success = iface_.mkdirhier(args.ctx, args.path, args.perms);
          result.setSuccessIsSet(true);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing mkdirhier", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing mkdirhier");
          oprot.writeMessageBegin(new TMessage("mkdirhier", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("mkdirhier", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class refreshNodes implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        refreshNodes_args args = new refreshNodes_args();
        args.read(iprot);
        iprot.readMessageEnd();
        refreshNodes_result result = new refreshNodes_result();
        try {
          iface_.refreshNodes(args.ctx);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing refreshNodes", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing refreshNodes");
          oprot.writeMessageBegin(new TMessage("refreshNodes", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("refreshNodes", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class rename implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        rename_args args = new rename_args();
        args.read(iprot);
        iprot.readMessageEnd();
        rename_result result = new rename_result();
        try {
          result.success = iface_.rename(args.ctx, args.path, args.newPath);
          result.setSuccessIsSet(true);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing rename", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing rename");
          oprot.writeMessageBegin(new TMessage("rename", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("rename", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class reportBadBlocks implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        reportBadBlocks_args args = new reportBadBlocks_args();
        args.read(iprot);
        iprot.readMessageEnd();
        reportBadBlocks_result result = new reportBadBlocks_result();
        try {
          iface_.reportBadBlocks(args.ctx, args.blocks);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing reportBadBlocks", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing reportBadBlocks");
          oprot.writeMessageBegin(new TMessage("reportBadBlocks", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("reportBadBlocks", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class stat implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        stat_args args = new stat_args();
        args.read(iprot);
        iprot.readMessageEnd();
        stat_result result = new stat_result();
        try {
          result.success = iface_.stat(args.ctx, args.path);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing stat", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing stat");
          oprot.writeMessageBegin(new TMessage("stat", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("stat", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class getContentSummary implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        getContentSummary_args args = new getContentSummary_args();
        args.read(iprot);
        iprot.readMessageEnd();
        getContentSummary_result result = new getContentSummary_result();
        try {
          result.success = iface_.getContentSummary(args.ctx, args.Path);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing getContentSummary", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing getContentSummary");
          oprot.writeMessageBegin(new TMessage("getContentSummary", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("getContentSummary", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class multiGetContentSummary implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        multiGetContentSummary_args args = new multiGetContentSummary_args();
        args.read(iprot);
        iprot.readMessageEnd();
        multiGetContentSummary_result result = new multiGetContentSummary_result();
        try {
          result.success = iface_.multiGetContentSummary(args.ctx, args.paths);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing multiGetContentSummary", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing multiGetContentSummary");
          oprot.writeMessageBegin(new TMessage("multiGetContentSummary", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("multiGetContentSummary", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class setQuota implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        setQuota_args args = new setQuota_args();
        args.read(iprot);
        iprot.readMessageEnd();
        setQuota_result result = new setQuota_result();
        try {
          iface_.setQuota(args.ctx, args.path, args.namespaceQuota, args.diskspaceQuota);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing setQuota", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing setQuota");
          oprot.writeMessageBegin(new TMessage("setQuota", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("setQuota", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class setReplication implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        setReplication_args args = new setReplication_args();
        args.read(iprot);
        iprot.readMessageEnd();
        setReplication_result result = new setReplication_result();
        try {
          result.success = iface_.setReplication(args.ctx, args.path, args.replication);
          result.setSuccessIsSet(true);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing setReplication", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing setReplication");
          oprot.writeMessageBegin(new TMessage("setReplication", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("setReplication", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class unlink implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        unlink_args args = new unlink_args();
        args.read(iprot);
        iprot.readMessageEnd();
        unlink_result result = new unlink_result();
        try {
          result.success = iface_.unlink(args.ctx, args.path, args.recursive);
          result.setSuccessIsSet(true);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing unlink", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing unlink");
          oprot.writeMessageBegin(new TMessage("unlink", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("unlink", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class utime implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        utime_args args = new utime_args();
        args.read(iprot);
        iprot.readMessageEnd();
        utime_result result = new utime_result();
        try {
          iface_.utime(args.ctx, args.path, args.atime, args.mtime);
        } catch (org.apache.hadoop.thriftfs.api.IOException err) {
          result.err = err;
        } catch (Throwable th) {
          LOGGER.error("Internal error processing utime", th);
          TApplicationException x = new TApplicationException(TApplicationException.INTERNAL_ERROR, "Internal error processing utime");
          oprot.writeMessageBegin(new TMessage("utime", TMessageType.EXCEPTION, seqid));
          x.write(oprot);
          oprot.writeMessageEnd();
          oprot.getTransport().flush();
          return;
        }
        oprot.writeMessageBegin(new TMessage("utime", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class datanodeUp implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        datanodeUp_args args = new datanodeUp_args();
        args.read(iprot);
        iprot.readMessageEnd();
        datanodeUp_result result = new datanodeUp_result();
        iface_.datanodeUp(args.name, args.storage, args.thriftPort);
        oprot.writeMessageBegin(new TMessage("datanodeUp", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

    private class datanodeDown implements ProcessFunction {
      public void process(int seqid, TProtocol iprot, TProtocol oprot) throws TException
      {
        datanodeDown_args args = new datanodeDown_args();
        args.read(iprot);
        iprot.readMessageEnd();
        datanodeDown_result result = new datanodeDown_result();
        iface_.datanodeDown(args.name, args.storage, args.thriftPort);
        oprot.writeMessageBegin(new TMessage("datanodeDown", TMessageType.REPLY, seqid));
        result.write(oprot);
        oprot.writeMessageEnd();
        oprot.getTransport().flush();
      }

    }

  }

  public static class chmod_args implements TBase<chmod_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("chmod_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField PERMS_FIELD_DESC = new TField("perms", TType.I16, (short)2);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path of the file or directory.
     */
    public String path;
    /**
     * New permissions for the file or directory.
     */
    public short perms;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path of the file or directory.
       */
      PATH((short)1, "path"),
      /**
       * New permissions for the file or directory.
       */
      PERMS((short)2, "perms");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __PERMS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.PERMS, new FieldMetaData("perms", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I16)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(chmod_args.class, metaDataMap);
    }

    public chmod_args() {
    }

    public chmod_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      short perms)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.perms = perms;
      setPermsIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public chmod_args(chmod_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.perms = other.perms;
    }

    public chmod_args deepCopy() {
      return new chmod_args(this);
    }

    @Deprecated
    public chmod_args clone() {
      return new chmod_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public chmod_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path of the file or directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path of the file or directory.
     */
    public chmod_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * New permissions for the file or directory.
     */
    public short getPerms() {
      return this.perms;
    }

    /**
     * New permissions for the file or directory.
     */
    public chmod_args setPerms(short perms) {
      this.perms = perms;
      setPermsIsSet(true);
      return this;
    }

    public void unsetPerms() {
      __isset_bit_vector.clear(__PERMS_ISSET_ID);
    }

    /** Returns true if field perms is set (has been asigned a value) and false otherwise */
    public boolean isSetPerms() {
      return __isset_bit_vector.get(__PERMS_ISSET_ID);
    }

    public void setPermsIsSet(boolean value) {
      __isset_bit_vector.set(__PERMS_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case PERMS:
        if (value == null) {
          unsetPerms();
        } else {
          setPerms((Short)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case PERMS:
        return new Short(getPerms());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case PERMS:
        return isSetPerms();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof chmod_args)
        return this.equals((chmod_args)that);
      return false;
    }

    public boolean equals(chmod_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_perms = true;
      boolean that_present_perms = true;
      if (this_present_perms || that_present_perms) {
        if (!(this_present_perms && that_present_perms))
          return false;
        if (this.perms != that.perms)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PERMS:
              if (field.type == TType.I16) {
                this.perms = iprot.readI16();
                setPermsIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(PERMS_FIELD_DESC);
      oprot.writeI16(this.perms);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("chmod_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("perms:");
      sb.append(this.perms);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class chmod_result implements TBase<chmod_result._Fields>, java.io.Serializable, Cloneable, Comparable<chmod_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("chmod_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(chmod_result.class, metaDataMap);
    }

    public chmod_result() {
    }

    public chmod_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public chmod_result(chmod_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public chmod_result deepCopy() {
      return new chmod_result(this);
    }

    @Deprecated
    public chmod_result clone() {
      return new chmod_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public chmod_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof chmod_result)
        return this.equals((chmod_result)that);
      return false;
    }

    public boolean equals(chmod_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(chmod_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      chmod_result typedOther = (chmod_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("chmod_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class chown_args implements TBase<chown_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("chown_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField OWNER_FIELD_DESC = new TField("owner", TType.STRING, (short)2);
    private static final TField GROUP_FIELD_DESC = new TField("group", TType.STRING, (short)3);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path to the file or directory
     */
    public String path;
    /**
     * New owner.
     */
    public String owner;
    /**
     * New group.
     */
    public String group;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path to the file or directory
       */
      PATH((short)1, "path"),
      /**
       * New owner.
       */
      OWNER((short)2, "owner"),
      /**
       * New group.
       */
      GROUP((short)3, "group");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.OWNER, new FieldMetaData("owner", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.GROUP, new FieldMetaData("group", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(chown_args.class, metaDataMap);
    }

    public chown_args() {
    }

    public chown_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      String owner,
      String group)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.owner = owner;
      this.group = group;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public chown_args(chown_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      if (other.isSetOwner()) {
        this.owner = other.owner;
      }
      if (other.isSetGroup()) {
        this.group = other.group;
      }
    }

    public chown_args deepCopy() {
      return new chown_args(this);
    }

    @Deprecated
    public chown_args clone() {
      return new chown_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public chown_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path to the file or directory
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path to the file or directory
     */
    public chown_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * New owner.
     */
    public String getOwner() {
      return this.owner;
    }

    /**
     * New owner.
     */
    public chown_args setOwner(String owner) {
      this.owner = owner;
      return this;
    }

    public void unsetOwner() {
      this.owner = null;
    }

    /** Returns true if field owner is set (has been asigned a value) and false otherwise */
    public boolean isSetOwner() {
      return this.owner != null;
    }

    public void setOwnerIsSet(boolean value) {
      if (!value) {
        this.owner = null;
      }
    }

    /**
     * New group.
     */
    public String getGroup() {
      return this.group;
    }

    /**
     * New group.
     */
    public chown_args setGroup(String group) {
      this.group = group;
      return this;
    }

    public void unsetGroup() {
      this.group = null;
    }

    /** Returns true if field group is set (has been asigned a value) and false otherwise */
    public boolean isSetGroup() {
      return this.group != null;
    }

    public void setGroupIsSet(boolean value) {
      if (!value) {
        this.group = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case OWNER:
        if (value == null) {
          unsetOwner();
        } else {
          setOwner((String)value);
        }
        break;

      case GROUP:
        if (value == null) {
          unsetGroup();
        } else {
          setGroup((String)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case OWNER:
        return getOwner();

      case GROUP:
        return getGroup();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case OWNER:
        return isSetOwner();
      case GROUP:
        return isSetGroup();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof chown_args)
        return this.equals((chown_args)that);
      return false;
    }

    public boolean equals(chown_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_owner = true && this.isSetOwner();
      boolean that_present_owner = true && that.isSetOwner();
      if (this_present_owner || that_present_owner) {
        if (!(this_present_owner && that_present_owner))
          return false;
        if (!this.owner.equals(that.owner))
          return false;
      }

      boolean this_present_group = true && this.isSetGroup();
      boolean that_present_group = true && that.isSetGroup();
      if (this_present_group || that_present_group) {
        if (!(this_present_group && that_present_group))
          return false;
        if (!this.group.equals(that.group))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case OWNER:
              if (field.type == TType.STRING) {
                this.owner = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case GROUP:
              if (field.type == TType.STRING) {
                this.group = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      if (this.owner != null) {
        oprot.writeFieldBegin(OWNER_FIELD_DESC);
        oprot.writeString(this.owner);
        oprot.writeFieldEnd();
      }
      if (this.group != null) {
        oprot.writeFieldBegin(GROUP_FIELD_DESC);
        oprot.writeString(this.group);
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("chown_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("owner:");
      if (this.owner == null) {
        sb.append("null");
      } else {
        sb.append(this.owner);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("group:");
      if (this.group == null) {
        sb.append("null");
      } else {
        sb.append(this.group);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class chown_result implements TBase<chown_result._Fields>, java.io.Serializable, Cloneable, Comparable<chown_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("chown_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(chown_result.class, metaDataMap);
    }

    public chown_result() {
    }

    public chown_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public chown_result(chown_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public chown_result deepCopy() {
      return new chown_result(this);
    }

    @Deprecated
    public chown_result clone() {
      return new chown_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public chown_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof chown_result)
        return this.equals((chown_result)that);
      return false;
    }

    public boolean equals(chown_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(chown_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      chown_result typedOther = (chown_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("chown_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class df_args implements TBase<df_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("df_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(df_args.class, metaDataMap);
    }

    public df_args() {
    }

    public df_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx)
    {
      this();
      this.ctx = ctx;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public df_args(df_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
    }

    public df_args deepCopy() {
      return new df_args(this);
    }

    @Deprecated
    public df_args clone() {
      return new df_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public df_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof df_args)
        return this.equals((df_args)that);
      return false;
    }

    public boolean equals(df_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("df_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class df_result implements TBase<df_result._Fields>, java.io.Serializable, Cloneable, Comparable<df_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("df_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.LIST, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public List<Long> success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new FieldValueMetaData(TType.I64))));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(df_result.class, metaDataMap);
    }

    public df_result() {
    }

    public df_result(
      List<Long> success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public df_result(df_result other) {
      if (other.isSetSuccess()) {
        List<Long> __this__success = new ArrayList<Long>();
        for (Long other_element : other.success) {
          __this__success.add(other_element);
        }
        this.success = __this__success;
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public df_result deepCopy() {
      return new df_result(this);
    }

    @Deprecated
    public df_result clone() {
      return new df_result(this);
    }

    public int getSuccessSize() {
      return (this.success == null) ? 0 : this.success.size();
    }

    public java.util.Iterator<Long> getSuccessIterator() {
      return (this.success == null) ? null : this.success.iterator();
    }

    public void addToSuccess(long elem) {
      if (this.success == null) {
        this.success = new ArrayList<Long>();
      }
      this.success.add(elem);
    }

    public List<Long> getSuccess() {
      return this.success;
    }

    public df_result setSuccess(List<Long> success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public df_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((List<Long>)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof df_result)
        return this.equals((df_result)that);
      return false;
    }

    public boolean equals(df_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(df_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      df_result typedOther = (df_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.LIST) {
                {
                  TList _list4 = iprot.readListBegin();
                  this.success = new ArrayList<Long>(_list4.size);
                  for (int _i5 = 0; _i5 < _list4.size; ++_i5)
                  {
                    long _elem6;
                    _elem6 = iprot.readI64();
                    this.success.add(_elem6);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.I64, this.success.size()));
          for (long _iter7 : this.success)
          {
            oprot.writeI64(_iter7);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("df_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class enterSafeMode_args implements TBase<enterSafeMode_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("enterSafeMode_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(enterSafeMode_args.class, metaDataMap);
    }

    public enterSafeMode_args() {
    }

    public enterSafeMode_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx)
    {
      this();
      this.ctx = ctx;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public enterSafeMode_args(enterSafeMode_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
    }

    public enterSafeMode_args deepCopy() {
      return new enterSafeMode_args(this);
    }

    @Deprecated
    public enterSafeMode_args clone() {
      return new enterSafeMode_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public enterSafeMode_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof enterSafeMode_args)
        return this.equals((enterSafeMode_args)that);
      return false;
    }

    public boolean equals(enterSafeMode_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("enterSafeMode_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class enterSafeMode_result implements TBase<enterSafeMode_result._Fields>, java.io.Serializable, Cloneable, Comparable<enterSafeMode_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("enterSafeMode_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(enterSafeMode_result.class, metaDataMap);
    }

    public enterSafeMode_result() {
    }

    public enterSafeMode_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public enterSafeMode_result(enterSafeMode_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public enterSafeMode_result deepCopy() {
      return new enterSafeMode_result(this);
    }

    @Deprecated
    public enterSafeMode_result clone() {
      return new enterSafeMode_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public enterSafeMode_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof enterSafeMode_result)
        return this.equals((enterSafeMode_result)that);
      return false;
    }

    public boolean equals(enterSafeMode_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(enterSafeMode_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      enterSafeMode_result typedOther = (enterSafeMode_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("enterSafeMode_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getBlocks_args implements TBase<getBlocks_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("getBlocks_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField OFFSET_FIELD_DESC = new TField("offset", TType.I64, (short)2);
    private static final TField LENGTH_FIELD_DESC = new TField("length", TType.I64, (short)3);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path to the file.
     */
    public String path;
    /**
     * Offset of the region.
     */
    public long offset;
    /**
     * Length of the region
     */
    public long length;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path to the file.
       */
      PATH((short)1, "path"),
      /**
       * Offset of the region.
       */
      OFFSET((short)2, "offset"),
      /**
       * Length of the region
       */
      LENGTH((short)3, "length");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __OFFSET_ISSET_ID = 0;
    private static final int __LENGTH_ISSET_ID = 1;
    private BitSet __isset_bit_vector = new BitSet(2);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.OFFSET, new FieldMetaData("offset", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
      put(_Fields.LENGTH, new FieldMetaData("length", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getBlocks_args.class, metaDataMap);
    }

    public getBlocks_args() {
    }

    public getBlocks_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      long offset,
      long length)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.offset = offset;
      setOffsetIsSet(true);
      this.length = length;
      setLengthIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getBlocks_args(getBlocks_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.offset = other.offset;
      this.length = other.length;
    }

    public getBlocks_args deepCopy() {
      return new getBlocks_args(this);
    }

    @Deprecated
    public getBlocks_args clone() {
      return new getBlocks_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public getBlocks_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path to the file.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path to the file.
     */
    public getBlocks_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * Offset of the region.
     */
    public long getOffset() {
      return this.offset;
    }

    /**
     * Offset of the region.
     */
    public getBlocks_args setOffset(long offset) {
      this.offset = offset;
      setOffsetIsSet(true);
      return this;
    }

    public void unsetOffset() {
      __isset_bit_vector.clear(__OFFSET_ISSET_ID);
    }

    /** Returns true if field offset is set (has been asigned a value) and false otherwise */
    public boolean isSetOffset() {
      return __isset_bit_vector.get(__OFFSET_ISSET_ID);
    }

    public void setOffsetIsSet(boolean value) {
      __isset_bit_vector.set(__OFFSET_ISSET_ID, value);
    }

    /**
     * Length of the region
     */
    public long getLength() {
      return this.length;
    }

    /**
     * Length of the region
     */
    public getBlocks_args setLength(long length) {
      this.length = length;
      setLengthIsSet(true);
      return this;
    }

    public void unsetLength() {
      __isset_bit_vector.clear(__LENGTH_ISSET_ID);
    }

    /** Returns true if field length is set (has been asigned a value) and false otherwise */
    public boolean isSetLength() {
      return __isset_bit_vector.get(__LENGTH_ISSET_ID);
    }

    public void setLengthIsSet(boolean value) {
      __isset_bit_vector.set(__LENGTH_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case OFFSET:
        if (value == null) {
          unsetOffset();
        } else {
          setOffset((Long)value);
        }
        break;

      case LENGTH:
        if (value == null) {
          unsetLength();
        } else {
          setLength((Long)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case OFFSET:
        return new Long(getOffset());

      case LENGTH:
        return new Long(getLength());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case OFFSET:
        return isSetOffset();
      case LENGTH:
        return isSetLength();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getBlocks_args)
        return this.equals((getBlocks_args)that);
      return false;
    }

    public boolean equals(getBlocks_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_offset = true;
      boolean that_present_offset = true;
      if (this_present_offset || that_present_offset) {
        if (!(this_present_offset && that_present_offset))
          return false;
        if (this.offset != that.offset)
          return false;
      }

      boolean this_present_length = true;
      boolean that_present_length = true;
      if (this_present_length || that_present_length) {
        if (!(this_present_length && that_present_length))
          return false;
        if (this.length != that.length)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case OFFSET:
              if (field.type == TType.I64) {
                this.offset = iprot.readI64();
                setOffsetIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case LENGTH:
              if (field.type == TType.I64) {
                this.length = iprot.readI64();
                setLengthIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(OFFSET_FIELD_DESC);
      oprot.writeI64(this.offset);
      oprot.writeFieldEnd();
      oprot.writeFieldBegin(LENGTH_FIELD_DESC);
      oprot.writeI64(this.length);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getBlocks_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("offset:");
      sb.append(this.offset);
      first = false;
      if (!first) sb.append(", ");
      sb.append("length:");
      sb.append(this.length);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getBlocks_result implements TBase<getBlocks_result._Fields>, java.io.Serializable, Cloneable, Comparable<getBlocks_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("getBlocks_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.LIST, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public List<Block> success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new StructMetaData(TType.STRUCT, Block.class))));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getBlocks_result.class, metaDataMap);
    }

    public getBlocks_result() {
    }

    public getBlocks_result(
      List<Block> success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getBlocks_result(getBlocks_result other) {
      if (other.isSetSuccess()) {
        List<Block> __this__success = new ArrayList<Block>();
        for (Block other_element : other.success) {
          __this__success.add(new Block(other_element));
        }
        this.success = __this__success;
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public getBlocks_result deepCopy() {
      return new getBlocks_result(this);
    }

    @Deprecated
    public getBlocks_result clone() {
      return new getBlocks_result(this);
    }

    public int getSuccessSize() {
      return (this.success == null) ? 0 : this.success.size();
    }

    public java.util.Iterator<Block> getSuccessIterator() {
      return (this.success == null) ? null : this.success.iterator();
    }

    public void addToSuccess(Block elem) {
      if (this.success == null) {
        this.success = new ArrayList<Block>();
      }
      this.success.add(elem);
    }

    public List<Block> getSuccess() {
      return this.success;
    }

    public getBlocks_result setSuccess(List<Block> success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public getBlocks_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((List<Block>)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getBlocks_result)
        return this.equals((getBlocks_result)that);
      return false;
    }

    public boolean equals(getBlocks_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(getBlocks_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      getBlocks_result typedOther = (getBlocks_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.LIST) {
                {
                  TList _list8 = iprot.readListBegin();
                  this.success = new ArrayList<Block>(_list8.size);
                  for (int _i9 = 0; _i9 < _list8.size; ++_i9)
                  {
                    Block _elem10;
                    _elem10 = new Block();
                    _elem10.read(iprot);
                    this.success.add(_elem10);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
          for (Block _iter11 : this.success)
          {
            _iter11.write(oprot);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getBlocks_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getDatanodeReport_args implements TBase<getDatanodeReport_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("getDatanodeReport_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField TYPE_FIELD_DESC = new TField("type", TType.I32, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Type of data nodes to return
     * information about.
     * 
     * @see DatanodeReportType
     */
    public DatanodeReportType type;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Type of data nodes to return
       * information about.
       * 
       * @see DatanodeReportType
       */
      TYPE((short)1, "type");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.TYPE, new FieldMetaData("type", TFieldRequirementType.DEFAULT, 
          new EnumMetaData(TType.ENUM, DatanodeReportType.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getDatanodeReport_args.class, metaDataMap);
    }

    public getDatanodeReport_args() {
    }

    public getDatanodeReport_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      DatanodeReportType type)
    {
      this();
      this.ctx = ctx;
      this.type = type;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getDatanodeReport_args(getDatanodeReport_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetType()) {
        this.type = other.type;
      }
    }

    public getDatanodeReport_args deepCopy() {
      return new getDatanodeReport_args(this);
    }

    @Deprecated
    public getDatanodeReport_args clone() {
      return new getDatanodeReport_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public getDatanodeReport_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Type of data nodes to return
     * information about.
     * 
     * @see DatanodeReportType
     */
    public DatanodeReportType getType() {
      return this.type;
    }

    /**
     * Type of data nodes to return
     * information about.
     * 
     * @see DatanodeReportType
     */
    public getDatanodeReport_args setType(DatanodeReportType type) {
      this.type = type;
      return this;
    }

    public void unsetType() {
      this.type = null;
    }

    /** Returns true if field type is set (has been asigned a value) and false otherwise */
    public boolean isSetType() {
      return this.type != null;
    }

    public void setTypeIsSet(boolean value) {
      if (!value) {
        this.type = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case TYPE:
        if (value == null) {
          unsetType();
        } else {
          setType((DatanodeReportType)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case TYPE:
        return getType();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case TYPE:
        return isSetType();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getDatanodeReport_args)
        return this.equals((getDatanodeReport_args)that);
      return false;
    }

    public boolean equals(getDatanodeReport_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_type = true && this.isSetType();
      boolean that_present_type = true && that.isSetType();
      if (this_present_type || that_present_type) {
        if (!(this_present_type && that_present_type))
          return false;
        if (!this.type.equals(that.type))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case TYPE:
              if (field.type == TType.I32) {
                this.type = DatanodeReportType.findByValue(iprot.readI32());
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.type != null) {
        oprot.writeFieldBegin(TYPE_FIELD_DESC);
        oprot.writeI32(this.type.getValue());
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getDatanodeReport_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("type:");
      if (this.type == null) {
        sb.append("null");
      } else {
        String type_name = type.name();
        if (type_name != null) {
          sb.append(type_name);
          sb.append(" (");
        }
        sb.append(this.type);
        if (type_name != null) {
          sb.append(")");
        }
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getDatanodeReport_result implements TBase<getDatanodeReport_result._Fields>, java.io.Serializable, Cloneable, Comparable<getDatanodeReport_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("getDatanodeReport_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.LIST, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public List<DatanodeInfo> success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new StructMetaData(TType.STRUCT, DatanodeInfo.class))));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getDatanodeReport_result.class, metaDataMap);
    }

    public getDatanodeReport_result() {
    }

    public getDatanodeReport_result(
      List<DatanodeInfo> success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getDatanodeReport_result(getDatanodeReport_result other) {
      if (other.isSetSuccess()) {
        List<DatanodeInfo> __this__success = new ArrayList<DatanodeInfo>();
        for (DatanodeInfo other_element : other.success) {
          __this__success.add(new DatanodeInfo(other_element));
        }
        this.success = __this__success;
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public getDatanodeReport_result deepCopy() {
      return new getDatanodeReport_result(this);
    }

    @Deprecated
    public getDatanodeReport_result clone() {
      return new getDatanodeReport_result(this);
    }

    public int getSuccessSize() {
      return (this.success == null) ? 0 : this.success.size();
    }

    public java.util.Iterator<DatanodeInfo> getSuccessIterator() {
      return (this.success == null) ? null : this.success.iterator();
    }

    public void addToSuccess(DatanodeInfo elem) {
      if (this.success == null) {
        this.success = new ArrayList<DatanodeInfo>();
      }
      this.success.add(elem);
    }

    public List<DatanodeInfo> getSuccess() {
      return this.success;
    }

    public getDatanodeReport_result setSuccess(List<DatanodeInfo> success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public getDatanodeReport_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((List<DatanodeInfo>)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getDatanodeReport_result)
        return this.equals((getDatanodeReport_result)that);
      return false;
    }

    public boolean equals(getDatanodeReport_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(getDatanodeReport_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      getDatanodeReport_result typedOther = (getDatanodeReport_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.LIST) {
                {
                  TList _list12 = iprot.readListBegin();
                  this.success = new ArrayList<DatanodeInfo>(_list12.size);
                  for (int _i13 = 0; _i13 < _list12.size; ++_i13)
                  {
                    DatanodeInfo _elem14;
                    _elem14 = new DatanodeInfo();
                    _elem14.read(iprot);
                    this.success.add(_elem14);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
          for (DatanodeInfo _iter15 : this.success)
          {
            _iter15.write(oprot);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getDatanodeReport_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getHealthReport_args implements TBase<getHealthReport_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("getHealthReport_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getHealthReport_args.class, metaDataMap);
    }

    public getHealthReport_args() {
    }

    public getHealthReport_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx)
    {
      this();
      this.ctx = ctx;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getHealthReport_args(getHealthReport_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
    }

    public getHealthReport_args deepCopy() {
      return new getHealthReport_args(this);
    }

    @Deprecated
    public getHealthReport_args clone() {
      return new getHealthReport_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public getHealthReport_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getHealthReport_args)
        return this.equals((getHealthReport_args)that);
      return false;
    }

    public boolean equals(getHealthReport_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getHealthReport_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getHealthReport_result implements TBase<getHealthReport_result._Fields>, java.io.Serializable, Cloneable, Comparable<getHealthReport_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("getHealthReport_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.STRUCT, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public DFSHealthReport success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, DFSHealthReport.class)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getHealthReport_result.class, metaDataMap);
    }

    public getHealthReport_result() {
    }

    public getHealthReport_result(
      DFSHealthReport success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getHealthReport_result(getHealthReport_result other) {
      if (other.isSetSuccess()) {
        this.success = new DFSHealthReport(other.success);
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public getHealthReport_result deepCopy() {
      return new getHealthReport_result(this);
    }

    @Deprecated
    public getHealthReport_result clone() {
      return new getHealthReport_result(this);
    }

    public DFSHealthReport getSuccess() {
      return this.success;
    }

    public getHealthReport_result setSuccess(DFSHealthReport success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public getHealthReport_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((DFSHealthReport)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getHealthReport_result)
        return this.equals((getHealthReport_result)that);
      return false;
    }

    public boolean equals(getHealthReport_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(getHealthReport_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      getHealthReport_result typedOther = (getHealthReport_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.STRUCT) {
                this.success = new DFSHealthReport();
                this.success.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        this.success.write(oprot);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getHealthReport_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getPreferredBlockSize_args implements TBase<getPreferredBlockSize_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("getPreferredBlockSize_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path to the file.
     */
    public String path;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path to the file.
       */
      PATH((short)1, "path");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getPreferredBlockSize_args.class, metaDataMap);
    }

    public getPreferredBlockSize_args() {
    }

    public getPreferredBlockSize_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path)
    {
      this();
      this.ctx = ctx;
      this.path = path;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getPreferredBlockSize_args(getPreferredBlockSize_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
    }

    public getPreferredBlockSize_args deepCopy() {
      return new getPreferredBlockSize_args(this);
    }

    @Deprecated
    public getPreferredBlockSize_args clone() {
      return new getPreferredBlockSize_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public getPreferredBlockSize_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path to the file.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path to the file.
     */
    public getPreferredBlockSize_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getPreferredBlockSize_args)
        return this.equals((getPreferredBlockSize_args)that);
      return false;
    }

    public boolean equals(getPreferredBlockSize_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getPreferredBlockSize_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getPreferredBlockSize_result implements TBase<getPreferredBlockSize_result._Fields>, java.io.Serializable, Cloneable, Comparable<getPreferredBlockSize_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("getPreferredBlockSize_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.I64, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public long success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __SUCCESS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getPreferredBlockSize_result.class, metaDataMap);
    }

    public getPreferredBlockSize_result() {
    }

    public getPreferredBlockSize_result(
      long success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      setSuccessIsSet(true);
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getPreferredBlockSize_result(getPreferredBlockSize_result other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      this.success = other.success;
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public getPreferredBlockSize_result deepCopy() {
      return new getPreferredBlockSize_result(this);
    }

    @Deprecated
    public getPreferredBlockSize_result clone() {
      return new getPreferredBlockSize_result(this);
    }

    public long getSuccess() {
      return this.success;
    }

    public getPreferredBlockSize_result setSuccess(long success) {
      this.success = success;
      setSuccessIsSet(true);
      return this;
    }

    public void unsetSuccess() {
      __isset_bit_vector.clear(__SUCCESS_ISSET_ID);
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return __isset_bit_vector.get(__SUCCESS_ISSET_ID);
    }

    public void setSuccessIsSet(boolean value) {
      __isset_bit_vector.set(__SUCCESS_ISSET_ID, value);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public getPreferredBlockSize_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Long)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return new Long(getSuccess());

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getPreferredBlockSize_result)
        return this.equals((getPreferredBlockSize_result)that);
      return false;
    }

    public boolean equals(getPreferredBlockSize_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true;
      boolean that_present_success = true;
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (this.success != that.success)
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(getPreferredBlockSize_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      getPreferredBlockSize_result typedOther = (getPreferredBlockSize_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.I64) {
                this.success = iprot.readI64();
                setSuccessIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        oprot.writeI64(this.success);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getPreferredBlockSize_result(");
      boolean first = true;

      sb.append("success:");
      sb.append(this.success);
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class isInSafeMode_args implements TBase<isInSafeMode_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("isInSafeMode_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(isInSafeMode_args.class, metaDataMap);
    }

    public isInSafeMode_args() {
    }

    public isInSafeMode_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx)
    {
      this();
      this.ctx = ctx;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public isInSafeMode_args(isInSafeMode_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
    }

    public isInSafeMode_args deepCopy() {
      return new isInSafeMode_args(this);
    }

    @Deprecated
    public isInSafeMode_args clone() {
      return new isInSafeMode_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public isInSafeMode_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof isInSafeMode_args)
        return this.equals((isInSafeMode_args)that);
      return false;
    }

    public boolean equals(isInSafeMode_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("isInSafeMode_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class isInSafeMode_result implements TBase<isInSafeMode_result._Fields>, java.io.Serializable, Cloneable, Comparable<isInSafeMode_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("isInSafeMode_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.BOOL, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public boolean success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __SUCCESS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.BOOL)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(isInSafeMode_result.class, metaDataMap);
    }

    public isInSafeMode_result() {
    }

    public isInSafeMode_result(
      boolean success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      setSuccessIsSet(true);
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public isInSafeMode_result(isInSafeMode_result other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      this.success = other.success;
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public isInSafeMode_result deepCopy() {
      return new isInSafeMode_result(this);
    }

    @Deprecated
    public isInSafeMode_result clone() {
      return new isInSafeMode_result(this);
    }

    public boolean isSuccess() {
      return this.success;
    }

    public isInSafeMode_result setSuccess(boolean success) {
      this.success = success;
      setSuccessIsSet(true);
      return this;
    }

    public void unsetSuccess() {
      __isset_bit_vector.clear(__SUCCESS_ISSET_ID);
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return __isset_bit_vector.get(__SUCCESS_ISSET_ID);
    }

    public void setSuccessIsSet(boolean value) {
      __isset_bit_vector.set(__SUCCESS_ISSET_ID, value);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public isInSafeMode_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Boolean)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return new Boolean(isSuccess());

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof isInSafeMode_result)
        return this.equals((isInSafeMode_result)that);
      return false;
    }

    public boolean equals(isInSafeMode_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true;
      boolean that_present_success = true;
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (this.success != that.success)
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(isInSafeMode_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      isInSafeMode_result typedOther = (isInSafeMode_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.BOOL) {
                this.success = iprot.readBool();
                setSuccessIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        oprot.writeBool(this.success);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("isInSafeMode_result(");
      boolean first = true;

      sb.append("success:");
      sb.append(this.success);
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class leaveSafeMode_args implements TBase<leaveSafeMode_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("leaveSafeMode_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(leaveSafeMode_args.class, metaDataMap);
    }

    public leaveSafeMode_args() {
    }

    public leaveSafeMode_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx)
    {
      this();
      this.ctx = ctx;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public leaveSafeMode_args(leaveSafeMode_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
    }

    public leaveSafeMode_args deepCopy() {
      return new leaveSafeMode_args(this);
    }

    @Deprecated
    public leaveSafeMode_args clone() {
      return new leaveSafeMode_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public leaveSafeMode_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof leaveSafeMode_args)
        return this.equals((leaveSafeMode_args)that);
      return false;
    }

    public boolean equals(leaveSafeMode_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("leaveSafeMode_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class leaveSafeMode_result implements TBase<leaveSafeMode_result._Fields>, java.io.Serializable, Cloneable, Comparable<leaveSafeMode_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("leaveSafeMode_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(leaveSafeMode_result.class, metaDataMap);
    }

    public leaveSafeMode_result() {
    }

    public leaveSafeMode_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public leaveSafeMode_result(leaveSafeMode_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public leaveSafeMode_result deepCopy() {
      return new leaveSafeMode_result(this);
    }

    @Deprecated
    public leaveSafeMode_result clone() {
      return new leaveSafeMode_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public leaveSafeMode_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof leaveSafeMode_result)
        return this.equals((leaveSafeMode_result)that);
      return false;
    }

    public boolean equals(leaveSafeMode_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(leaveSafeMode_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      leaveSafeMode_result typedOther = (leaveSafeMode_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("leaveSafeMode_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class ls_args implements TBase<ls_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("ls_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path to the directory.
     */
    public String path;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path to the directory.
       */
      PATH((short)1, "path");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(ls_args.class, metaDataMap);
    }

    public ls_args() {
    }

    public ls_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path)
    {
      this();
      this.ctx = ctx;
      this.path = path;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public ls_args(ls_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
    }

    public ls_args deepCopy() {
      return new ls_args(this);
    }

    @Deprecated
    public ls_args clone() {
      return new ls_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public ls_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path to the directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path to the directory.
     */
    public ls_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof ls_args)
        return this.equals((ls_args)that);
      return false;
    }

    public boolean equals(ls_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("ls_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class ls_result implements TBase<ls_result._Fields>, java.io.Serializable, Cloneable, Comparable<ls_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("ls_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.LIST, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public List<Stat> success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new StructMetaData(TType.STRUCT, Stat.class))));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(ls_result.class, metaDataMap);
    }

    public ls_result() {
    }

    public ls_result(
      List<Stat> success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public ls_result(ls_result other) {
      if (other.isSetSuccess()) {
        List<Stat> __this__success = new ArrayList<Stat>();
        for (Stat other_element : other.success) {
          __this__success.add(new Stat(other_element));
        }
        this.success = __this__success;
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public ls_result deepCopy() {
      return new ls_result(this);
    }

    @Deprecated
    public ls_result clone() {
      return new ls_result(this);
    }

    public int getSuccessSize() {
      return (this.success == null) ? 0 : this.success.size();
    }

    public java.util.Iterator<Stat> getSuccessIterator() {
      return (this.success == null) ? null : this.success.iterator();
    }

    public void addToSuccess(Stat elem) {
      if (this.success == null) {
        this.success = new ArrayList<Stat>();
      }
      this.success.add(elem);
    }

    public List<Stat> getSuccess() {
      return this.success;
    }

    public ls_result setSuccess(List<Stat> success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public ls_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((List<Stat>)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof ls_result)
        return this.equals((ls_result)that);
      return false;
    }

    public boolean equals(ls_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(ls_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      ls_result typedOther = (ls_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.LIST) {
                {
                  TList _list16 = iprot.readListBegin();
                  this.success = new ArrayList<Stat>(_list16.size);
                  for (int _i17 = 0; _i17 < _list16.size; ++_i17)
                  {
                    Stat _elem18;
                    _elem18 = new Stat();
                    _elem18.read(iprot);
                    this.success.add(_elem18);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
          for (Stat _iter19 : this.success)
          {
            _iter19.write(oprot);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("ls_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class mkdirhier_args implements TBase<mkdirhier_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("mkdirhier_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField PERMS_FIELD_DESC = new TField("perms", TType.I16, (short)2);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path to the directory.
     */
    public String path;
    /**
     * Access permissions of the directory.
     */
    public short perms;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path to the directory.
       */
      PATH((short)1, "path"),
      /**
       * Access permissions of the directory.
       */
      PERMS((short)2, "perms");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __PERMS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.PERMS, new FieldMetaData("perms", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I16)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(mkdirhier_args.class, metaDataMap);
    }

    public mkdirhier_args() {
    }

    public mkdirhier_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      short perms)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.perms = perms;
      setPermsIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public mkdirhier_args(mkdirhier_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.perms = other.perms;
    }

    public mkdirhier_args deepCopy() {
      return new mkdirhier_args(this);
    }

    @Deprecated
    public mkdirhier_args clone() {
      return new mkdirhier_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public mkdirhier_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path to the directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path to the directory.
     */
    public mkdirhier_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * Access permissions of the directory.
     */
    public short getPerms() {
      return this.perms;
    }

    /**
     * Access permissions of the directory.
     */
    public mkdirhier_args setPerms(short perms) {
      this.perms = perms;
      setPermsIsSet(true);
      return this;
    }

    public void unsetPerms() {
      __isset_bit_vector.clear(__PERMS_ISSET_ID);
    }

    /** Returns true if field perms is set (has been asigned a value) and false otherwise */
    public boolean isSetPerms() {
      return __isset_bit_vector.get(__PERMS_ISSET_ID);
    }

    public void setPermsIsSet(boolean value) {
      __isset_bit_vector.set(__PERMS_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case PERMS:
        if (value == null) {
          unsetPerms();
        } else {
          setPerms((Short)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case PERMS:
        return new Short(getPerms());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case PERMS:
        return isSetPerms();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof mkdirhier_args)
        return this.equals((mkdirhier_args)that);
      return false;
    }

    public boolean equals(mkdirhier_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_perms = true;
      boolean that_present_perms = true;
      if (this_present_perms || that_present_perms) {
        if (!(this_present_perms && that_present_perms))
          return false;
        if (this.perms != that.perms)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PERMS:
              if (field.type == TType.I16) {
                this.perms = iprot.readI16();
                setPermsIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(PERMS_FIELD_DESC);
      oprot.writeI16(this.perms);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("mkdirhier_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("perms:");
      sb.append(this.perms);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class mkdirhier_result implements TBase<mkdirhier_result._Fields>, java.io.Serializable, Cloneable, Comparable<mkdirhier_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("mkdirhier_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.BOOL, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public boolean success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __SUCCESS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.BOOL)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(mkdirhier_result.class, metaDataMap);
    }

    public mkdirhier_result() {
    }

    public mkdirhier_result(
      boolean success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      setSuccessIsSet(true);
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public mkdirhier_result(mkdirhier_result other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      this.success = other.success;
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public mkdirhier_result deepCopy() {
      return new mkdirhier_result(this);
    }

    @Deprecated
    public mkdirhier_result clone() {
      return new mkdirhier_result(this);
    }

    public boolean isSuccess() {
      return this.success;
    }

    public mkdirhier_result setSuccess(boolean success) {
      this.success = success;
      setSuccessIsSet(true);
      return this;
    }

    public void unsetSuccess() {
      __isset_bit_vector.clear(__SUCCESS_ISSET_ID);
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return __isset_bit_vector.get(__SUCCESS_ISSET_ID);
    }

    public void setSuccessIsSet(boolean value) {
      __isset_bit_vector.set(__SUCCESS_ISSET_ID, value);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public mkdirhier_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Boolean)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return new Boolean(isSuccess());

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof mkdirhier_result)
        return this.equals((mkdirhier_result)that);
      return false;
    }

    public boolean equals(mkdirhier_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true;
      boolean that_present_success = true;
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (this.success != that.success)
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(mkdirhier_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      mkdirhier_result typedOther = (mkdirhier_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.BOOL) {
                this.success = iprot.readBool();
                setSuccessIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        oprot.writeBool(this.success);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("mkdirhier_result(");
      boolean first = true;

      sb.append("success:");
      sb.append(this.success);
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class refreshNodes_args implements TBase<refreshNodes_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("refreshNodes_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(refreshNodes_args.class, metaDataMap);
    }

    public refreshNodes_args() {
    }

    public refreshNodes_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx)
    {
      this();
      this.ctx = ctx;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public refreshNodes_args(refreshNodes_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
    }

    public refreshNodes_args deepCopy() {
      return new refreshNodes_args(this);
    }

    @Deprecated
    public refreshNodes_args clone() {
      return new refreshNodes_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public refreshNodes_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof refreshNodes_args)
        return this.equals((refreshNodes_args)that);
      return false;
    }

    public boolean equals(refreshNodes_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("refreshNodes_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class refreshNodes_result implements TBase<refreshNodes_result._Fields>, java.io.Serializable, Cloneable, Comparable<refreshNodes_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("refreshNodes_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(refreshNodes_result.class, metaDataMap);
    }

    public refreshNodes_result() {
    }

    public refreshNodes_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public refreshNodes_result(refreshNodes_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public refreshNodes_result deepCopy() {
      return new refreshNodes_result(this);
    }

    @Deprecated
    public refreshNodes_result clone() {
      return new refreshNodes_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public refreshNodes_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof refreshNodes_result)
        return this.equals((refreshNodes_result)that);
      return false;
    }

    public boolean equals(refreshNodes_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(refreshNodes_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      refreshNodes_result typedOther = (refreshNodes_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("refreshNodes_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class rename_args implements TBase<rename_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("rename_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField NEW_PATH_FIELD_DESC = new TField("newPath", TType.STRING, (short)2);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path to existing file or directory.
     */
    public String path;
    /**
     * New path.
     */
    public String newPath;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path to existing file or directory.
       */
      PATH((short)1, "path"),
      /**
       * New path.
       */
      NEW_PATH((short)2, "newPath");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.NEW_PATH, new FieldMetaData("newPath", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(rename_args.class, metaDataMap);
    }

    public rename_args() {
    }

    public rename_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      String newPath)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.newPath = newPath;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public rename_args(rename_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      if (other.isSetNewPath()) {
        this.newPath = other.newPath;
      }
    }

    public rename_args deepCopy() {
      return new rename_args(this);
    }

    @Deprecated
    public rename_args clone() {
      return new rename_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public rename_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path to existing file or directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path to existing file or directory.
     */
    public rename_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * New path.
     */
    public String getNewPath() {
      return this.newPath;
    }

    /**
     * New path.
     */
    public rename_args setNewPath(String newPath) {
      this.newPath = newPath;
      return this;
    }

    public void unsetNewPath() {
      this.newPath = null;
    }

    /** Returns true if field newPath is set (has been asigned a value) and false otherwise */
    public boolean isSetNewPath() {
      return this.newPath != null;
    }

    public void setNewPathIsSet(boolean value) {
      if (!value) {
        this.newPath = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case NEW_PATH:
        if (value == null) {
          unsetNewPath();
        } else {
          setNewPath((String)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case NEW_PATH:
        return getNewPath();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case NEW_PATH:
        return isSetNewPath();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof rename_args)
        return this.equals((rename_args)that);
      return false;
    }

    public boolean equals(rename_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_newPath = true && this.isSetNewPath();
      boolean that_present_newPath = true && that.isSetNewPath();
      if (this_present_newPath || that_present_newPath) {
        if (!(this_present_newPath && that_present_newPath))
          return false;
        if (!this.newPath.equals(that.newPath))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case NEW_PATH:
              if (field.type == TType.STRING) {
                this.newPath = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      if (this.newPath != null) {
        oprot.writeFieldBegin(NEW_PATH_FIELD_DESC);
        oprot.writeString(this.newPath);
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("rename_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("newPath:");
      if (this.newPath == null) {
        sb.append("null");
      } else {
        sb.append(this.newPath);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class rename_result implements TBase<rename_result._Fields>, java.io.Serializable, Cloneable, Comparable<rename_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("rename_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.BOOL, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public boolean success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __SUCCESS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.BOOL)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(rename_result.class, metaDataMap);
    }

    public rename_result() {
    }

    public rename_result(
      boolean success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      setSuccessIsSet(true);
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public rename_result(rename_result other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      this.success = other.success;
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public rename_result deepCopy() {
      return new rename_result(this);
    }

    @Deprecated
    public rename_result clone() {
      return new rename_result(this);
    }

    public boolean isSuccess() {
      return this.success;
    }

    public rename_result setSuccess(boolean success) {
      this.success = success;
      setSuccessIsSet(true);
      return this;
    }

    public void unsetSuccess() {
      __isset_bit_vector.clear(__SUCCESS_ISSET_ID);
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return __isset_bit_vector.get(__SUCCESS_ISSET_ID);
    }

    public void setSuccessIsSet(boolean value) {
      __isset_bit_vector.set(__SUCCESS_ISSET_ID, value);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public rename_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Boolean)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return new Boolean(isSuccess());

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof rename_result)
        return this.equals((rename_result)that);
      return false;
    }

    public boolean equals(rename_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true;
      boolean that_present_success = true;
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (this.success != that.success)
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(rename_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      rename_result typedOther = (rename_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.BOOL) {
                this.success = iprot.readBool();
                setSuccessIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        oprot.writeBool(this.success);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("rename_result(");
      boolean first = true;

      sb.append("success:");
      sb.append(this.success);
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class reportBadBlocks_args implements TBase<reportBadBlocks_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("reportBadBlocks_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField BLOCKS_FIELD_DESC = new TField("blocks", TType.LIST, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * List of corrupted blocks.
     */
    public List<Block> blocks;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * List of corrupted blocks.
       */
      BLOCKS((short)1, "blocks");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.BLOCKS, new FieldMetaData("blocks", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new StructMetaData(TType.STRUCT, Block.class))));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(reportBadBlocks_args.class, metaDataMap);
    }

    public reportBadBlocks_args() {
    }

    public reportBadBlocks_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      List<Block> blocks)
    {
      this();
      this.ctx = ctx;
      this.blocks = blocks;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public reportBadBlocks_args(reportBadBlocks_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetBlocks()) {
        List<Block> __this__blocks = new ArrayList<Block>();
        for (Block other_element : other.blocks) {
          __this__blocks.add(new Block(other_element));
        }
        this.blocks = __this__blocks;
      }
    }

    public reportBadBlocks_args deepCopy() {
      return new reportBadBlocks_args(this);
    }

    @Deprecated
    public reportBadBlocks_args clone() {
      return new reportBadBlocks_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public reportBadBlocks_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public int getBlocksSize() {
      return (this.blocks == null) ? 0 : this.blocks.size();
    }

    public java.util.Iterator<Block> getBlocksIterator() {
      return (this.blocks == null) ? null : this.blocks.iterator();
    }

    public void addToBlocks(Block elem) {
      if (this.blocks == null) {
        this.blocks = new ArrayList<Block>();
      }
      this.blocks.add(elem);
    }

    /**
     * List of corrupted blocks.
     */
    public List<Block> getBlocks() {
      return this.blocks;
    }

    /**
     * List of corrupted blocks.
     */
    public reportBadBlocks_args setBlocks(List<Block> blocks) {
      this.blocks = blocks;
      return this;
    }

    public void unsetBlocks() {
      this.blocks = null;
    }

    /** Returns true if field blocks is set (has been asigned a value) and false otherwise */
    public boolean isSetBlocks() {
      return this.blocks != null;
    }

    public void setBlocksIsSet(boolean value) {
      if (!value) {
        this.blocks = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case BLOCKS:
        if (value == null) {
          unsetBlocks();
        } else {
          setBlocks((List<Block>)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case BLOCKS:
        return getBlocks();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case BLOCKS:
        return isSetBlocks();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof reportBadBlocks_args)
        return this.equals((reportBadBlocks_args)that);
      return false;
    }

    public boolean equals(reportBadBlocks_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_blocks = true && this.isSetBlocks();
      boolean that_present_blocks = true && that.isSetBlocks();
      if (this_present_blocks || that_present_blocks) {
        if (!(this_present_blocks && that_present_blocks))
          return false;
        if (!this.blocks.equals(that.blocks))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case BLOCKS:
              if (field.type == TType.LIST) {
                {
                  TList _list20 = iprot.readListBegin();
                  this.blocks = new ArrayList<Block>(_list20.size);
                  for (int _i21 = 0; _i21 < _list20.size; ++_i21)
                  {
                    Block _elem22;
                    _elem22 = new Block();
                    _elem22.read(iprot);
                    this.blocks.add(_elem22);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.blocks != null) {
        oprot.writeFieldBegin(BLOCKS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.STRUCT, this.blocks.size()));
          for (Block _iter23 : this.blocks)
          {
            _iter23.write(oprot);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("reportBadBlocks_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("blocks:");
      if (this.blocks == null) {
        sb.append("null");
      } else {
        sb.append(this.blocks);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class reportBadBlocks_result implements TBase<reportBadBlocks_result._Fields>, java.io.Serializable, Cloneable, Comparable<reportBadBlocks_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("reportBadBlocks_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(reportBadBlocks_result.class, metaDataMap);
    }

    public reportBadBlocks_result() {
    }

    public reportBadBlocks_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public reportBadBlocks_result(reportBadBlocks_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public reportBadBlocks_result deepCopy() {
      return new reportBadBlocks_result(this);
    }

    @Deprecated
    public reportBadBlocks_result clone() {
      return new reportBadBlocks_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public reportBadBlocks_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof reportBadBlocks_result)
        return this.equals((reportBadBlocks_result)that);
      return false;
    }

    public boolean equals(reportBadBlocks_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(reportBadBlocks_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      reportBadBlocks_result typedOther = (reportBadBlocks_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("reportBadBlocks_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class stat_args implements TBase<stat_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("stat_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path of the file or directory.
     */
    public String path;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path of the file or directory.
       */
      PATH((short)1, "path");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(stat_args.class, metaDataMap);
    }

    public stat_args() {
    }

    public stat_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path)
    {
      this();
      this.ctx = ctx;
      this.path = path;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public stat_args(stat_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
    }

    public stat_args deepCopy() {
      return new stat_args(this);
    }

    @Deprecated
    public stat_args clone() {
      return new stat_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public stat_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path of the file or directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path of the file or directory.
     */
    public stat_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof stat_args)
        return this.equals((stat_args)that);
      return false;
    }

    public boolean equals(stat_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("stat_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class stat_result implements TBase<stat_result._Fields>, java.io.Serializable, Cloneable, Comparable<stat_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("stat_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.STRUCT, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public Stat success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, Stat.class)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(stat_result.class, metaDataMap);
    }

    public stat_result() {
    }

    public stat_result(
      Stat success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public stat_result(stat_result other) {
      if (other.isSetSuccess()) {
        this.success = new Stat(other.success);
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public stat_result deepCopy() {
      return new stat_result(this);
    }

    @Deprecated
    public stat_result clone() {
      return new stat_result(this);
    }

    public Stat getSuccess() {
      return this.success;
    }

    public stat_result setSuccess(Stat success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public stat_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Stat)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof stat_result)
        return this.equals((stat_result)that);
      return false;
    }

    public boolean equals(stat_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(stat_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      stat_result typedOther = (stat_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.STRUCT) {
                this.success = new Stat();
                this.success.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        this.success.write(oprot);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("stat_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getContentSummary_args implements TBase<getContentSummary_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("getContentSummary_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("Path", TType.STRING, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    public String Path;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      PATH((short)1, "Path");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("Path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getContentSummary_args.class, metaDataMap);
    }

    public getContentSummary_args() {
    }

    public getContentSummary_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String Path)
    {
      this();
      this.ctx = ctx;
      this.Path = Path;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getContentSummary_args(getContentSummary_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.Path = other.Path;
      }
    }

    public getContentSummary_args deepCopy() {
      return new getContentSummary_args(this);
    }

    @Deprecated
    public getContentSummary_args clone() {
      return new getContentSummary_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public getContentSummary_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public String getPath() {
      return this.Path;
    }

    public getContentSummary_args setPath(String Path) {
      this.Path = Path;
      return this;
    }

    public void unsetPath() {
      this.Path = null;
    }

    /** Returns true if field Path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.Path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.Path = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getContentSummary_args)
        return this.equals((getContentSummary_args)that);
      return false;
    }

    public boolean equals(getContentSummary_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_Path = true && this.isSetPath();
      boolean that_present_Path = true && that.isSetPath();
      if (this_present_Path || that_present_Path) {
        if (!(this_present_Path && that_present_Path))
          return false;
        if (!this.Path.equals(that.Path))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.Path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.Path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.Path);
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getContentSummary_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("Path:");
      if (this.Path == null) {
        sb.append("null");
      } else {
        sb.append(this.Path);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class getContentSummary_result implements TBase<getContentSummary_result._Fields>, java.io.Serializable, Cloneable, Comparable<getContentSummary_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("getContentSummary_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.STRUCT, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public ContentSummary success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, ContentSummary.class)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(getContentSummary_result.class, metaDataMap);
    }

    public getContentSummary_result() {
    }

    public getContentSummary_result(
      ContentSummary success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public getContentSummary_result(getContentSummary_result other) {
      if (other.isSetSuccess()) {
        this.success = new ContentSummary(other.success);
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public getContentSummary_result deepCopy() {
      return new getContentSummary_result(this);
    }

    @Deprecated
    public getContentSummary_result clone() {
      return new getContentSummary_result(this);
    }

    public ContentSummary getSuccess() {
      return this.success;
    }

    public getContentSummary_result setSuccess(ContentSummary success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public getContentSummary_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((ContentSummary)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof getContentSummary_result)
        return this.equals((getContentSummary_result)that);
      return false;
    }

    public boolean equals(getContentSummary_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(getContentSummary_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      getContentSummary_result typedOther = (getContentSummary_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.STRUCT) {
                this.success = new ContentSummary();
                this.success.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        this.success.write(oprot);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("getContentSummary_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class multiGetContentSummary_args implements TBase<multiGetContentSummary_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("multiGetContentSummary_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATHS_FIELD_DESC = new TField("paths", TType.LIST, (short)1);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    public List<String> paths;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      PATHS((short)1, "paths");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATHS, new FieldMetaData("paths", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new FieldValueMetaData(TType.STRING))));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(multiGetContentSummary_args.class, metaDataMap);
    }

    public multiGetContentSummary_args() {
    }

    public multiGetContentSummary_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      List<String> paths)
    {
      this();
      this.ctx = ctx;
      this.paths = paths;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public multiGetContentSummary_args(multiGetContentSummary_args other) {
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPaths()) {
        List<String> __this__paths = new ArrayList<String>();
        for (String other_element : other.paths) {
          __this__paths.add(other_element);
        }
        this.paths = __this__paths;
      }
    }

    public multiGetContentSummary_args deepCopy() {
      return new multiGetContentSummary_args(this);
    }

    @Deprecated
    public multiGetContentSummary_args clone() {
      return new multiGetContentSummary_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public multiGetContentSummary_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    public int getPathsSize() {
      return (this.paths == null) ? 0 : this.paths.size();
    }

    public java.util.Iterator<String> getPathsIterator() {
      return (this.paths == null) ? null : this.paths.iterator();
    }

    public void addToPaths(String elem) {
      if (this.paths == null) {
        this.paths = new ArrayList<String>();
      }
      this.paths.add(elem);
    }

    public List<String> getPaths() {
      return this.paths;
    }

    public multiGetContentSummary_args setPaths(List<String> paths) {
      this.paths = paths;
      return this;
    }

    public void unsetPaths() {
      this.paths = null;
    }

    /** Returns true if field paths is set (has been asigned a value) and false otherwise */
    public boolean isSetPaths() {
      return this.paths != null;
    }

    public void setPathsIsSet(boolean value) {
      if (!value) {
        this.paths = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATHS:
        if (value == null) {
          unsetPaths();
        } else {
          setPaths((List<String>)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATHS:
        return getPaths();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATHS:
        return isSetPaths();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof multiGetContentSummary_args)
        return this.equals((multiGetContentSummary_args)that);
      return false;
    }

    public boolean equals(multiGetContentSummary_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_paths = true && this.isSetPaths();
      boolean that_present_paths = true && that.isSetPaths();
      if (this_present_paths || that_present_paths) {
        if (!(this_present_paths && that_present_paths))
          return false;
        if (!this.paths.equals(that.paths))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATHS:
              if (field.type == TType.LIST) {
                {
                  TList _list24 = iprot.readListBegin();
                  this.paths = new ArrayList<String>(_list24.size);
                  for (int _i25 = 0; _i25 < _list24.size; ++_i25)
                  {
                    String _elem26;
                    _elem26 = iprot.readString();
                    this.paths.add(_elem26);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.paths != null) {
        oprot.writeFieldBegin(PATHS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.STRING, this.paths.size()));
          for (String _iter27 : this.paths)
          {
            oprot.writeString(_iter27);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      }
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("multiGetContentSummary_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("paths:");
      if (this.paths == null) {
        sb.append("null");
      } else {
        sb.append(this.paths);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class multiGetContentSummary_result implements TBase<multiGetContentSummary_result._Fields>, java.io.Serializable, Cloneable, Comparable<multiGetContentSummary_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("multiGetContentSummary_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.LIST, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public List<ContentSummary> success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new ListMetaData(TType.LIST, 
              new StructMetaData(TType.STRUCT, ContentSummary.class))));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(multiGetContentSummary_result.class, metaDataMap);
    }

    public multiGetContentSummary_result() {
    }

    public multiGetContentSummary_result(
      List<ContentSummary> success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public multiGetContentSummary_result(multiGetContentSummary_result other) {
      if (other.isSetSuccess()) {
        List<ContentSummary> __this__success = new ArrayList<ContentSummary>();
        for (ContentSummary other_element : other.success) {
          __this__success.add(new ContentSummary(other_element));
        }
        this.success = __this__success;
      }
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public multiGetContentSummary_result deepCopy() {
      return new multiGetContentSummary_result(this);
    }

    @Deprecated
    public multiGetContentSummary_result clone() {
      return new multiGetContentSummary_result(this);
    }

    public int getSuccessSize() {
      return (this.success == null) ? 0 : this.success.size();
    }

    public java.util.Iterator<ContentSummary> getSuccessIterator() {
      return (this.success == null) ? null : this.success.iterator();
    }

    public void addToSuccess(ContentSummary elem) {
      if (this.success == null) {
        this.success = new ArrayList<ContentSummary>();
      }
      this.success.add(elem);
    }

    public List<ContentSummary> getSuccess() {
      return this.success;
    }

    public multiGetContentSummary_result setSuccess(List<ContentSummary> success) {
      this.success = success;
      return this;
    }

    public void unsetSuccess() {
      this.success = null;
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return this.success != null;
    }

    public void setSuccessIsSet(boolean value) {
      if (!value) {
        this.success = null;
      }
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public multiGetContentSummary_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((List<ContentSummary>)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return getSuccess();

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof multiGetContentSummary_result)
        return this.equals((multiGetContentSummary_result)that);
      return false;
    }

    public boolean equals(multiGetContentSummary_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true && this.isSetSuccess();
      boolean that_present_success = true && that.isSetSuccess();
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (!this.success.equals(that.success))
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(multiGetContentSummary_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      multiGetContentSummary_result typedOther = (multiGetContentSummary_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.LIST) {
                {
                  TList _list28 = iprot.readListBegin();
                  this.success = new ArrayList<ContentSummary>(_list28.size);
                  for (int _i29 = 0; _i29 < _list28.size; ++_i29)
                  {
                    ContentSummary _elem30;
                    _elem30 = new ContentSummary();
                    _elem30.read(iprot);
                    this.success.add(_elem30);
                  }
                  iprot.readListEnd();
                }
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        {
          oprot.writeListBegin(new TList(TType.STRUCT, this.success.size()));
          for (ContentSummary _iter31 : this.success)
          {
            _iter31.write(oprot);
          }
          oprot.writeListEnd();
        }
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("multiGetContentSummary_result(");
      boolean first = true;

      sb.append("success:");
      if (this.success == null) {
        sb.append("null");
      } else {
        sb.append(this.success);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class setQuota_args implements TBase<setQuota_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("setQuota_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField NAMESPACE_QUOTA_FIELD_DESC = new TField("namespaceQuota", TType.I64, (short)2);
    private static final TField DISKSPACE_QUOTA_FIELD_DESC = new TField("diskspaceQuota", TType.I64, (short)3);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path of the directory.
     */
    public String path;
    /**
     * Limit on the number of names in the directory.
     */
    public long namespaceQuota;
    /**
     * Limit on disk space occupied by all the files in the
     * directory.
     */
    public long diskspaceQuota;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path of the directory.
       */
      PATH((short)1, "path"),
      /**
       * Limit on the number of names in the directory.
       */
      NAMESPACE_QUOTA((short)2, "namespaceQuota"),
      /**
       * Limit on disk space occupied by all the files in the
       * directory.
       */
      DISKSPACE_QUOTA((short)3, "diskspaceQuota");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __NAMESPACEQUOTA_ISSET_ID = 0;
    private static final int __DISKSPACEQUOTA_ISSET_ID = 1;
    private BitSet __isset_bit_vector = new BitSet(2);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.NAMESPACE_QUOTA, new FieldMetaData("namespaceQuota", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
      put(_Fields.DISKSPACE_QUOTA, new FieldMetaData("diskspaceQuota", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(setQuota_args.class, metaDataMap);
    }

    public setQuota_args() {
    }

    public setQuota_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      long namespaceQuota,
      long diskspaceQuota)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.namespaceQuota = namespaceQuota;
      setNamespaceQuotaIsSet(true);
      this.diskspaceQuota = diskspaceQuota;
      setDiskspaceQuotaIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public setQuota_args(setQuota_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.namespaceQuota = other.namespaceQuota;
      this.diskspaceQuota = other.diskspaceQuota;
    }

    public setQuota_args deepCopy() {
      return new setQuota_args(this);
    }

    @Deprecated
    public setQuota_args clone() {
      return new setQuota_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public setQuota_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path of the directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path of the directory.
     */
    public setQuota_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * Limit on the number of names in the directory.
     */
    public long getNamespaceQuota() {
      return this.namespaceQuota;
    }

    /**
     * Limit on the number of names in the directory.
     */
    public setQuota_args setNamespaceQuota(long namespaceQuota) {
      this.namespaceQuota = namespaceQuota;
      setNamespaceQuotaIsSet(true);
      return this;
    }

    public void unsetNamespaceQuota() {
      __isset_bit_vector.clear(__NAMESPACEQUOTA_ISSET_ID);
    }

    /** Returns true if field namespaceQuota is set (has been asigned a value) and false otherwise */
    public boolean isSetNamespaceQuota() {
      return __isset_bit_vector.get(__NAMESPACEQUOTA_ISSET_ID);
    }

    public void setNamespaceQuotaIsSet(boolean value) {
      __isset_bit_vector.set(__NAMESPACEQUOTA_ISSET_ID, value);
    }

    /**
     * Limit on disk space occupied by all the files in the
     * directory.
     */
    public long getDiskspaceQuota() {
      return this.diskspaceQuota;
    }

    /**
     * Limit on disk space occupied by all the files in the
     * directory.
     */
    public setQuota_args setDiskspaceQuota(long diskspaceQuota) {
      this.diskspaceQuota = diskspaceQuota;
      setDiskspaceQuotaIsSet(true);
      return this;
    }

    public void unsetDiskspaceQuota() {
      __isset_bit_vector.clear(__DISKSPACEQUOTA_ISSET_ID);
    }

    /** Returns true if field diskspaceQuota is set (has been asigned a value) and false otherwise */
    public boolean isSetDiskspaceQuota() {
      return __isset_bit_vector.get(__DISKSPACEQUOTA_ISSET_ID);
    }

    public void setDiskspaceQuotaIsSet(boolean value) {
      __isset_bit_vector.set(__DISKSPACEQUOTA_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case NAMESPACE_QUOTA:
        if (value == null) {
          unsetNamespaceQuota();
        } else {
          setNamespaceQuota((Long)value);
        }
        break;

      case DISKSPACE_QUOTA:
        if (value == null) {
          unsetDiskspaceQuota();
        } else {
          setDiskspaceQuota((Long)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case NAMESPACE_QUOTA:
        return new Long(getNamespaceQuota());

      case DISKSPACE_QUOTA:
        return new Long(getDiskspaceQuota());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case NAMESPACE_QUOTA:
        return isSetNamespaceQuota();
      case DISKSPACE_QUOTA:
        return isSetDiskspaceQuota();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof setQuota_args)
        return this.equals((setQuota_args)that);
      return false;
    }

    public boolean equals(setQuota_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_namespaceQuota = true;
      boolean that_present_namespaceQuota = true;
      if (this_present_namespaceQuota || that_present_namespaceQuota) {
        if (!(this_present_namespaceQuota && that_present_namespaceQuota))
          return false;
        if (this.namespaceQuota != that.namespaceQuota)
          return false;
      }

      boolean this_present_diskspaceQuota = true;
      boolean that_present_diskspaceQuota = true;
      if (this_present_diskspaceQuota || that_present_diskspaceQuota) {
        if (!(this_present_diskspaceQuota && that_present_diskspaceQuota))
          return false;
        if (this.diskspaceQuota != that.diskspaceQuota)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case NAMESPACE_QUOTA:
              if (field.type == TType.I64) {
                this.namespaceQuota = iprot.readI64();
                setNamespaceQuotaIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case DISKSPACE_QUOTA:
              if (field.type == TType.I64) {
                this.diskspaceQuota = iprot.readI64();
                setDiskspaceQuotaIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(NAMESPACE_QUOTA_FIELD_DESC);
      oprot.writeI64(this.namespaceQuota);
      oprot.writeFieldEnd();
      oprot.writeFieldBegin(DISKSPACE_QUOTA_FIELD_DESC);
      oprot.writeI64(this.diskspaceQuota);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("setQuota_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("namespaceQuota:");
      sb.append(this.namespaceQuota);
      first = false;
      if (!first) sb.append(", ");
      sb.append("diskspaceQuota:");
      sb.append(this.diskspaceQuota);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class setQuota_result implements TBase<setQuota_result._Fields>, java.io.Serializable, Cloneable, Comparable<setQuota_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("setQuota_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(setQuota_result.class, metaDataMap);
    }

    public setQuota_result() {
    }

    public setQuota_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public setQuota_result(setQuota_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public setQuota_result deepCopy() {
      return new setQuota_result(this);
    }

    @Deprecated
    public setQuota_result clone() {
      return new setQuota_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public setQuota_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof setQuota_result)
        return this.equals((setQuota_result)that);
      return false;
    }

    public boolean equals(setQuota_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(setQuota_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      setQuota_result typedOther = (setQuota_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("setQuota_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class setReplication_args implements TBase<setReplication_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("setReplication_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField REPLICATION_FIELD_DESC = new TField("replication", TType.I16, (short)2);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path of the file.
     */
    public String path;
    /**
     * New replication factor.
     */
    public short replication;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path of the file.
       */
      PATH((short)1, "path"),
      /**
       * New replication factor.
       */
      REPLICATION((short)2, "replication");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __REPLICATION_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.REPLICATION, new FieldMetaData("replication", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I16)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(setReplication_args.class, metaDataMap);
    }

    public setReplication_args() {
    }

    public setReplication_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      short replication)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.replication = replication;
      setReplicationIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public setReplication_args(setReplication_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.replication = other.replication;
    }

    public setReplication_args deepCopy() {
      return new setReplication_args(this);
    }

    @Deprecated
    public setReplication_args clone() {
      return new setReplication_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public setReplication_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path of the file.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path of the file.
     */
    public setReplication_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * New replication factor.
     */
    public short getReplication() {
      return this.replication;
    }

    /**
     * New replication factor.
     */
    public setReplication_args setReplication(short replication) {
      this.replication = replication;
      setReplicationIsSet(true);
      return this;
    }

    public void unsetReplication() {
      __isset_bit_vector.clear(__REPLICATION_ISSET_ID);
    }

    /** Returns true if field replication is set (has been asigned a value) and false otherwise */
    public boolean isSetReplication() {
      return __isset_bit_vector.get(__REPLICATION_ISSET_ID);
    }

    public void setReplicationIsSet(boolean value) {
      __isset_bit_vector.set(__REPLICATION_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case REPLICATION:
        if (value == null) {
          unsetReplication();
        } else {
          setReplication((Short)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case REPLICATION:
        return new Short(getReplication());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case REPLICATION:
        return isSetReplication();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof setReplication_args)
        return this.equals((setReplication_args)that);
      return false;
    }

    public boolean equals(setReplication_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_replication = true;
      boolean that_present_replication = true;
      if (this_present_replication || that_present_replication) {
        if (!(this_present_replication && that_present_replication))
          return false;
        if (this.replication != that.replication)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case REPLICATION:
              if (field.type == TType.I16) {
                this.replication = iprot.readI16();
                setReplicationIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(REPLICATION_FIELD_DESC);
      oprot.writeI16(this.replication);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("setReplication_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("replication:");
      sb.append(this.replication);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class setReplication_result implements TBase<setReplication_result._Fields>, java.io.Serializable, Cloneable, Comparable<setReplication_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("setReplication_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.BOOL, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public boolean success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __SUCCESS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.BOOL)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(setReplication_result.class, metaDataMap);
    }

    public setReplication_result() {
    }

    public setReplication_result(
      boolean success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      setSuccessIsSet(true);
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public setReplication_result(setReplication_result other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      this.success = other.success;
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public setReplication_result deepCopy() {
      return new setReplication_result(this);
    }

    @Deprecated
    public setReplication_result clone() {
      return new setReplication_result(this);
    }

    public boolean isSuccess() {
      return this.success;
    }

    public setReplication_result setSuccess(boolean success) {
      this.success = success;
      setSuccessIsSet(true);
      return this;
    }

    public void unsetSuccess() {
      __isset_bit_vector.clear(__SUCCESS_ISSET_ID);
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return __isset_bit_vector.get(__SUCCESS_ISSET_ID);
    }

    public void setSuccessIsSet(boolean value) {
      __isset_bit_vector.set(__SUCCESS_ISSET_ID, value);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public setReplication_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Boolean)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return new Boolean(isSuccess());

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof setReplication_result)
        return this.equals((setReplication_result)that);
      return false;
    }

    public boolean equals(setReplication_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true;
      boolean that_present_success = true;
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (this.success != that.success)
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(setReplication_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      setReplication_result typedOther = (setReplication_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.BOOL) {
                this.success = iprot.readBool();
                setSuccessIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        oprot.writeBool(this.success);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("setReplication_result(");
      boolean first = true;

      sb.append("success:");
      sb.append(this.success);
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class unlink_args implements TBase<unlink_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("unlink_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField RECURSIVE_FIELD_DESC = new TField("recursive", TType.BOOL, (short)2);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path of the file or directory.
     */
    public String path;
    /**
     * Delete a non-empty directory recursively.
     */
    public boolean recursive;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path of the file or directory.
       */
      PATH((short)1, "path"),
      /**
       * Delete a non-empty directory recursively.
       */
      RECURSIVE((short)2, "recursive");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __RECURSIVE_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.RECURSIVE, new FieldMetaData("recursive", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.BOOL)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(unlink_args.class, metaDataMap);
    }

    public unlink_args() {
    }

    public unlink_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      boolean recursive)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.recursive = recursive;
      setRecursiveIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public unlink_args(unlink_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.recursive = other.recursive;
    }

    public unlink_args deepCopy() {
      return new unlink_args(this);
    }

    @Deprecated
    public unlink_args clone() {
      return new unlink_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public unlink_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path of the file or directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path of the file or directory.
     */
    public unlink_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * Delete a non-empty directory recursively.
     */
    public boolean isRecursive() {
      return this.recursive;
    }

    /**
     * Delete a non-empty directory recursively.
     */
    public unlink_args setRecursive(boolean recursive) {
      this.recursive = recursive;
      setRecursiveIsSet(true);
      return this;
    }

    public void unsetRecursive() {
      __isset_bit_vector.clear(__RECURSIVE_ISSET_ID);
    }

    /** Returns true if field recursive is set (has been asigned a value) and false otherwise */
    public boolean isSetRecursive() {
      return __isset_bit_vector.get(__RECURSIVE_ISSET_ID);
    }

    public void setRecursiveIsSet(boolean value) {
      __isset_bit_vector.set(__RECURSIVE_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case RECURSIVE:
        if (value == null) {
          unsetRecursive();
        } else {
          setRecursive((Boolean)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case RECURSIVE:
        return new Boolean(isRecursive());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case RECURSIVE:
        return isSetRecursive();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof unlink_args)
        return this.equals((unlink_args)that);
      return false;
    }

    public boolean equals(unlink_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_recursive = true;
      boolean that_present_recursive = true;
      if (this_present_recursive || that_present_recursive) {
        if (!(this_present_recursive && that_present_recursive))
          return false;
        if (this.recursive != that.recursive)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case RECURSIVE:
              if (field.type == TType.BOOL) {
                this.recursive = iprot.readBool();
                setRecursiveIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(RECURSIVE_FIELD_DESC);
      oprot.writeBool(this.recursive);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("unlink_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("recursive:");
      sb.append(this.recursive);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class unlink_result implements TBase<unlink_result._Fields>, java.io.Serializable, Cloneable, Comparable<unlink_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("unlink_result");

    private static final TField SUCCESS_FIELD_DESC = new TField("success", TType.BOOL, (short)0);
    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public boolean success;
    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      SUCCESS((short)0, "success"),
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __SUCCESS_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.SUCCESS, new FieldMetaData("success", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.BOOL)));
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(unlink_result.class, metaDataMap);
    }

    public unlink_result() {
    }

    public unlink_result(
      boolean success,
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.success = success;
      setSuccessIsSet(true);
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public unlink_result(unlink_result other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      this.success = other.success;
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public unlink_result deepCopy() {
      return new unlink_result(this);
    }

    @Deprecated
    public unlink_result clone() {
      return new unlink_result(this);
    }

    public boolean isSuccess() {
      return this.success;
    }

    public unlink_result setSuccess(boolean success) {
      this.success = success;
      setSuccessIsSet(true);
      return this;
    }

    public void unsetSuccess() {
      __isset_bit_vector.clear(__SUCCESS_ISSET_ID);
    }

    /** Returns true if field success is set (has been asigned a value) and false otherwise */
    public boolean isSetSuccess() {
      return __isset_bit_vector.get(__SUCCESS_ISSET_ID);
    }

    public void setSuccessIsSet(boolean value) {
      __isset_bit_vector.set(__SUCCESS_ISSET_ID, value);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public unlink_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case SUCCESS:
        if (value == null) {
          unsetSuccess();
        } else {
          setSuccess((Boolean)value);
        }
        break;

      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case SUCCESS:
        return new Boolean(isSuccess());

      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case SUCCESS:
        return isSetSuccess();
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof unlink_result)
        return this.equals((unlink_result)that);
      return false;
    }

    public boolean equals(unlink_result that) {
      if (that == null)
        return false;

      boolean this_present_success = true;
      boolean that_present_success = true;
      if (this_present_success || that_present_success) {
        if (!(this_present_success && that_present_success))
          return false;
        if (this.success != that.success)
          return false;
      }

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(unlink_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      unlink_result typedOther = (unlink_result)other;

      lastComparison = Boolean.valueOf(isSetSuccess()).compareTo(isSetSuccess());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(success, typedOther.success);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case SUCCESS:
              if (field.type == TType.BOOL) {
                this.success = iprot.readBool();
                setSuccessIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetSuccess()) {
        oprot.writeFieldBegin(SUCCESS_FIELD_DESC);
        oprot.writeBool(this.success);
        oprot.writeFieldEnd();
      } else if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("unlink_result(");
      boolean first = true;

      sb.append("success:");
      sb.append(this.success);
      first = false;
      if (!first) sb.append(", ");
      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class utime_args implements TBase<utime_args._Fields>, java.io.Serializable, Cloneable   {
    private static final TStruct STRUCT_DESC = new TStruct("utime_args");

    private static final TField CTX_FIELD_DESC = new TField("ctx", TType.STRUCT, (short)10);
    private static final TField PATH_FIELD_DESC = new TField("path", TType.STRING, (short)1);
    private static final TField ATIME_FIELD_DESC = new TField("atime", TType.I64, (short)2);
    private static final TField MTIME_FIELD_DESC = new TField("mtime", TType.I64, (short)3);

    public org.apache.hadoop.thriftfs.api.RequestContext ctx;
    /**
     * Path of the file or directory.
     */
    public String path;
    /**
     * Access time in milliseconds since 1970-01-01 00:00 UTC
     */
    public long atime;
    /**
     * Modification time in milliseconds since 1970-01-01 00:00 UTC
     */
    public long mtime;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      CTX((short)10, "ctx"),
      /**
       * Path of the file or directory.
       */
      PATH((short)1, "path"),
      /**
       * Access time in milliseconds since 1970-01-01 00:00 UTC
       */
      ATIME((short)2, "atime"),
      /**
       * Modification time in milliseconds since 1970-01-01 00:00 UTC
       */
      MTIME((short)3, "mtime");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __ATIME_ISSET_ID = 0;
    private static final int __MTIME_ISSET_ID = 1;
    private BitSet __isset_bit_vector = new BitSet(2);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.CTX, new FieldMetaData("ctx", TFieldRequirementType.DEFAULT, 
          new StructMetaData(TType.STRUCT, org.apache.hadoop.thriftfs.api.RequestContext.class)));
      put(_Fields.PATH, new FieldMetaData("path", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.ATIME, new FieldMetaData("atime", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
      put(_Fields.MTIME, new FieldMetaData("mtime", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I64)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(utime_args.class, metaDataMap);
    }

    public utime_args() {
    }

    public utime_args(
      org.apache.hadoop.thriftfs.api.RequestContext ctx,
      String path,
      long atime,
      long mtime)
    {
      this();
      this.ctx = ctx;
      this.path = path;
      this.atime = atime;
      setAtimeIsSet(true);
      this.mtime = mtime;
      setMtimeIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public utime_args(utime_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetCtx()) {
        this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext(other.ctx);
      }
      if (other.isSetPath()) {
        this.path = other.path;
      }
      this.atime = other.atime;
      this.mtime = other.mtime;
    }

    public utime_args deepCopy() {
      return new utime_args(this);
    }

    @Deprecated
    public utime_args clone() {
      return new utime_args(this);
    }

    public org.apache.hadoop.thriftfs.api.RequestContext getCtx() {
      return this.ctx;
    }

    public utime_args setCtx(org.apache.hadoop.thriftfs.api.RequestContext ctx) {
      this.ctx = ctx;
      return this;
    }

    public void unsetCtx() {
      this.ctx = null;
    }

    /** Returns true if field ctx is set (has been asigned a value) and false otherwise */
    public boolean isSetCtx() {
      return this.ctx != null;
    }

    public void setCtxIsSet(boolean value) {
      if (!value) {
        this.ctx = null;
      }
    }

    /**
     * Path of the file or directory.
     */
    public String getPath() {
      return this.path;
    }

    /**
     * Path of the file or directory.
     */
    public utime_args setPath(String path) {
      this.path = path;
      return this;
    }

    public void unsetPath() {
      this.path = null;
    }

    /** Returns true if field path is set (has been asigned a value) and false otherwise */
    public boolean isSetPath() {
      return this.path != null;
    }

    public void setPathIsSet(boolean value) {
      if (!value) {
        this.path = null;
      }
    }

    /**
     * Access time in milliseconds since 1970-01-01 00:00 UTC
     */
    public long getAtime() {
      return this.atime;
    }

    /**
     * Access time in milliseconds since 1970-01-01 00:00 UTC
     */
    public utime_args setAtime(long atime) {
      this.atime = atime;
      setAtimeIsSet(true);
      return this;
    }

    public void unsetAtime() {
      __isset_bit_vector.clear(__ATIME_ISSET_ID);
    }

    /** Returns true if field atime is set (has been asigned a value) and false otherwise */
    public boolean isSetAtime() {
      return __isset_bit_vector.get(__ATIME_ISSET_ID);
    }

    public void setAtimeIsSet(boolean value) {
      __isset_bit_vector.set(__ATIME_ISSET_ID, value);
    }

    /**
     * Modification time in milliseconds since 1970-01-01 00:00 UTC
     */
    public long getMtime() {
      return this.mtime;
    }

    /**
     * Modification time in milliseconds since 1970-01-01 00:00 UTC
     */
    public utime_args setMtime(long mtime) {
      this.mtime = mtime;
      setMtimeIsSet(true);
      return this;
    }

    public void unsetMtime() {
      __isset_bit_vector.clear(__MTIME_ISSET_ID);
    }

    /** Returns true if field mtime is set (has been asigned a value) and false otherwise */
    public boolean isSetMtime() {
      return __isset_bit_vector.get(__MTIME_ISSET_ID);
    }

    public void setMtimeIsSet(boolean value) {
      __isset_bit_vector.set(__MTIME_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case CTX:
        if (value == null) {
          unsetCtx();
        } else {
          setCtx((org.apache.hadoop.thriftfs.api.RequestContext)value);
        }
        break;

      case PATH:
        if (value == null) {
          unsetPath();
        } else {
          setPath((String)value);
        }
        break;

      case ATIME:
        if (value == null) {
          unsetAtime();
        } else {
          setAtime((Long)value);
        }
        break;

      case MTIME:
        if (value == null) {
          unsetMtime();
        } else {
          setMtime((Long)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case CTX:
        return getCtx();

      case PATH:
        return getPath();

      case ATIME:
        return new Long(getAtime());

      case MTIME:
        return new Long(getMtime());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case CTX:
        return isSetCtx();
      case PATH:
        return isSetPath();
      case ATIME:
        return isSetAtime();
      case MTIME:
        return isSetMtime();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof utime_args)
        return this.equals((utime_args)that);
      return false;
    }

    public boolean equals(utime_args that) {
      if (that == null)
        return false;

      boolean this_present_ctx = true && this.isSetCtx();
      boolean that_present_ctx = true && that.isSetCtx();
      if (this_present_ctx || that_present_ctx) {
        if (!(this_present_ctx && that_present_ctx))
          return false;
        if (!this.ctx.equals(that.ctx))
          return false;
      }

      boolean this_present_path = true && this.isSetPath();
      boolean that_present_path = true && that.isSetPath();
      if (this_present_path || that_present_path) {
        if (!(this_present_path && that_present_path))
          return false;
        if (!this.path.equals(that.path))
          return false;
      }

      boolean this_present_atime = true;
      boolean that_present_atime = true;
      if (this_present_atime || that_present_atime) {
        if (!(this_present_atime && that_present_atime))
          return false;
        if (this.atime != that.atime)
          return false;
      }

      boolean this_present_mtime = true;
      boolean that_present_mtime = true;
      if (this_present_mtime || that_present_mtime) {
        if (!(this_present_mtime && that_present_mtime))
          return false;
        if (this.mtime != that.mtime)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case CTX:
              if (field.type == TType.STRUCT) {
                this.ctx = new org.apache.hadoop.thriftfs.api.RequestContext();
                this.ctx.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case PATH:
              if (field.type == TType.STRING) {
                this.path = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case ATIME:
              if (field.type == TType.I64) {
                this.atime = iprot.readI64();
                setAtimeIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case MTIME:
              if (field.type == TType.I64) {
                this.mtime = iprot.readI64();
                setMtimeIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.path != null) {
        oprot.writeFieldBegin(PATH_FIELD_DESC);
        oprot.writeString(this.path);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(ATIME_FIELD_DESC);
      oprot.writeI64(this.atime);
      oprot.writeFieldEnd();
      oprot.writeFieldBegin(MTIME_FIELD_DESC);
      oprot.writeI64(this.mtime);
      oprot.writeFieldEnd();
      if (this.ctx != null) {
        oprot.writeFieldBegin(CTX_FIELD_DESC);
        this.ctx.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("utime_args(");
      boolean first = true;

      sb.append("ctx:");
      if (this.ctx == null) {
        sb.append("null");
      } else {
        sb.append(this.ctx);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("path:");
      if (this.path == null) {
        sb.append("null");
      } else {
        sb.append(this.path);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("atime:");
      sb.append(this.atime);
      first = false;
      if (!first) sb.append(", ");
      sb.append("mtime:");
      sb.append(this.mtime);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class utime_result implements TBase<utime_result._Fields>, java.io.Serializable, Cloneable, Comparable<utime_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("utime_result");

    private static final TField ERR_FIELD_DESC = new TField("err", TType.STRUCT, (short)1);

    public org.apache.hadoop.thriftfs.api.IOException err;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      ERR((short)1, "err");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.ERR, new FieldMetaData("err", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRUCT)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(utime_result.class, metaDataMap);
    }

    public utime_result() {
    }

    public utime_result(
      org.apache.hadoop.thriftfs.api.IOException err)
    {
      this();
      this.err = err;
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public utime_result(utime_result other) {
      if (other.isSetErr()) {
        this.err = new org.apache.hadoop.thriftfs.api.IOException(other.err);
      }
    }

    public utime_result deepCopy() {
      return new utime_result(this);
    }

    @Deprecated
    public utime_result clone() {
      return new utime_result(this);
    }

    public org.apache.hadoop.thriftfs.api.IOException getErr() {
      return this.err;
    }

    public utime_result setErr(org.apache.hadoop.thriftfs.api.IOException err) {
      this.err = err;
      return this;
    }

    public void unsetErr() {
      this.err = null;
    }

    /** Returns true if field err is set (has been asigned a value) and false otherwise */
    public boolean isSetErr() {
      return this.err != null;
    }

    public void setErrIsSet(boolean value) {
      if (!value) {
        this.err = null;
      }
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case ERR:
        if (value == null) {
          unsetErr();
        } else {
          setErr((org.apache.hadoop.thriftfs.api.IOException)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case ERR:
        return getErr();

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case ERR:
        return isSetErr();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof utime_result)
        return this.equals((utime_result)that);
      return false;
    }

    public boolean equals(utime_result that) {
      if (that == null)
        return false;

      boolean this_present_err = true && this.isSetErr();
      boolean that_present_err = true && that.isSetErr();
      if (this_present_err || that_present_err) {
        if (!(this_present_err && that_present_err))
          return false;
        if (!this.err.equals(that.err))
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(utime_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      utime_result typedOther = (utime_result)other;

      lastComparison = Boolean.valueOf(isSetErr()).compareTo(isSetErr());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(err, typedOther.err);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case ERR:
              if (field.type == TType.STRUCT) {
                this.err = new org.apache.hadoop.thriftfs.api.IOException();
                this.err.read(iprot);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      if (this.isSetErr()) {
        oprot.writeFieldBegin(ERR_FIELD_DESC);
        this.err.write(oprot);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("utime_result(");
      boolean first = true;

      sb.append("err:");
      if (this.err == null) {
        sb.append("null");
      } else {
        sb.append(this.err);
      }
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class datanodeUp_args implements TBase<datanodeUp_args._Fields>, java.io.Serializable, Cloneable, Comparable<datanodeUp_args>   {
    private static final TStruct STRUCT_DESC = new TStruct("datanodeUp_args");

    private static final TField NAME_FIELD_DESC = new TField("name", TType.STRING, (short)1);
    private static final TField STORAGE_FIELD_DESC = new TField("storage", TType.STRING, (short)2);
    private static final TField THRIFT_PORT_FIELD_DESC = new TField("thriftPort", TType.I32, (short)3);

    /**
     * <host name>:<port number> of the datanode
     */
    public String name;
    /**
     * the storage id of the datanode
     */
    public String storage;
    /**
     * Thrift port of the datanode
     */
    public int thriftPort;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      /**
       * <host name>:<port number> of the datanode
       */
      NAME((short)1, "name"),
      /**
       * the storage id of the datanode
       */
      STORAGE((short)2, "storage"),
      /**
       * Thrift port of the datanode
       */
      THRIFT_PORT((short)3, "thriftPort");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __THRIFTPORT_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.NAME, new FieldMetaData("name", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.STORAGE, new FieldMetaData("storage", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.THRIFT_PORT, new FieldMetaData("thriftPort", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I32)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(datanodeUp_args.class, metaDataMap);
    }

    public datanodeUp_args() {
    }

    public datanodeUp_args(
      String name,
      String storage,
      int thriftPort)
    {
      this();
      this.name = name;
      this.storage = storage;
      this.thriftPort = thriftPort;
      setThriftPortIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public datanodeUp_args(datanodeUp_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetName()) {
        this.name = other.name;
      }
      if (other.isSetStorage()) {
        this.storage = other.storage;
      }
      this.thriftPort = other.thriftPort;
    }

    public datanodeUp_args deepCopy() {
      return new datanodeUp_args(this);
    }

    @Deprecated
    public datanodeUp_args clone() {
      return new datanodeUp_args(this);
    }

    /**
     * <host name>:<port number> of the datanode
     */
    public String getName() {
      return this.name;
    }

    /**
     * <host name>:<port number> of the datanode
     */
    public datanodeUp_args setName(String name) {
      this.name = name;
      return this;
    }

    public void unsetName() {
      this.name = null;
    }

    /** Returns true if field name is set (has been asigned a value) and false otherwise */
    public boolean isSetName() {
      return this.name != null;
    }

    public void setNameIsSet(boolean value) {
      if (!value) {
        this.name = null;
      }
    }

    /**
     * the storage id of the datanode
     */
    public String getStorage() {
      return this.storage;
    }

    /**
     * the storage id of the datanode
     */
    public datanodeUp_args setStorage(String storage) {
      this.storage = storage;
      return this;
    }

    public void unsetStorage() {
      this.storage = null;
    }

    /** Returns true if field storage is set (has been asigned a value) and false otherwise */
    public boolean isSetStorage() {
      return this.storage != null;
    }

    public void setStorageIsSet(boolean value) {
      if (!value) {
        this.storage = null;
      }
    }

    /**
     * Thrift port of the datanode
     */
    public int getThriftPort() {
      return this.thriftPort;
    }

    /**
     * Thrift port of the datanode
     */
    public datanodeUp_args setThriftPort(int thriftPort) {
      this.thriftPort = thriftPort;
      setThriftPortIsSet(true);
      return this;
    }

    public void unsetThriftPort() {
      __isset_bit_vector.clear(__THRIFTPORT_ISSET_ID);
    }

    /** Returns true if field thriftPort is set (has been asigned a value) and false otherwise */
    public boolean isSetThriftPort() {
      return __isset_bit_vector.get(__THRIFTPORT_ISSET_ID);
    }

    public void setThriftPortIsSet(boolean value) {
      __isset_bit_vector.set(__THRIFTPORT_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case NAME:
        if (value == null) {
          unsetName();
        } else {
          setName((String)value);
        }
        break;

      case STORAGE:
        if (value == null) {
          unsetStorage();
        } else {
          setStorage((String)value);
        }
        break;

      case THRIFT_PORT:
        if (value == null) {
          unsetThriftPort();
        } else {
          setThriftPort((Integer)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case NAME:
        return getName();

      case STORAGE:
        return getStorage();

      case THRIFT_PORT:
        return new Integer(getThriftPort());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case NAME:
        return isSetName();
      case STORAGE:
        return isSetStorage();
      case THRIFT_PORT:
        return isSetThriftPort();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof datanodeUp_args)
        return this.equals((datanodeUp_args)that);
      return false;
    }

    public boolean equals(datanodeUp_args that) {
      if (that == null)
        return false;

      boolean this_present_name = true && this.isSetName();
      boolean that_present_name = true && that.isSetName();
      if (this_present_name || that_present_name) {
        if (!(this_present_name && that_present_name))
          return false;
        if (!this.name.equals(that.name))
          return false;
      }

      boolean this_present_storage = true && this.isSetStorage();
      boolean that_present_storage = true && that.isSetStorage();
      if (this_present_storage || that_present_storage) {
        if (!(this_present_storage && that_present_storage))
          return false;
        if (!this.storage.equals(that.storage))
          return false;
      }

      boolean this_present_thriftPort = true;
      boolean that_present_thriftPort = true;
      if (this_present_thriftPort || that_present_thriftPort) {
        if (!(this_present_thriftPort && that_present_thriftPort))
          return false;
        if (this.thriftPort != that.thriftPort)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(datanodeUp_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      datanodeUp_args typedOther = (datanodeUp_args)other;

      lastComparison = Boolean.valueOf(isSetName()).compareTo(isSetName());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(name, typedOther.name);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetStorage()).compareTo(isSetStorage());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(storage, typedOther.storage);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetThriftPort()).compareTo(isSetThriftPort());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(thriftPort, typedOther.thriftPort);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case NAME:
              if (field.type == TType.STRING) {
                this.name = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case STORAGE:
              if (field.type == TType.STRING) {
                this.storage = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case THRIFT_PORT:
              if (field.type == TType.I32) {
                this.thriftPort = iprot.readI32();
                setThriftPortIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.name != null) {
        oprot.writeFieldBegin(NAME_FIELD_DESC);
        oprot.writeString(this.name);
        oprot.writeFieldEnd();
      }
      if (this.storage != null) {
        oprot.writeFieldBegin(STORAGE_FIELD_DESC);
        oprot.writeString(this.storage);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(THRIFT_PORT_FIELD_DESC);
      oprot.writeI32(this.thriftPort);
      oprot.writeFieldEnd();
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("datanodeUp_args(");
      boolean first = true;

      sb.append("name:");
      if (this.name == null) {
        sb.append("null");
      } else {
        sb.append(this.name);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("storage:");
      if (this.storage == null) {
        sb.append("null");
      } else {
        sb.append(this.storage);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("thriftPort:");
      sb.append(this.thriftPort);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class datanodeUp_result implements TBase<datanodeUp_result._Fields>, java.io.Serializable, Cloneable, Comparable<datanodeUp_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("datanodeUp_result");



    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
;

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }
    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
    }});

    static {
      FieldMetaData.addStructMetaDataMap(datanodeUp_result.class, metaDataMap);
    }

    public datanodeUp_result() {
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public datanodeUp_result(datanodeUp_result other) {
    }

    public datanodeUp_result deepCopy() {
      return new datanodeUp_result(this);
    }

    @Deprecated
    public datanodeUp_result clone() {
      return new datanodeUp_result(this);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof datanodeUp_result)
        return this.equals((datanodeUp_result)that);
      return false;
    }

    public boolean equals(datanodeUp_result that) {
      if (that == null)
        return false;

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(datanodeUp_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      datanodeUp_result typedOther = (datanodeUp_result)other;

      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("datanodeUp_result(");
      boolean first = true;

      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class datanodeDown_args implements TBase<datanodeDown_args._Fields>, java.io.Serializable, Cloneable, Comparable<datanodeDown_args>   {
    private static final TStruct STRUCT_DESC = new TStruct("datanodeDown_args");

    private static final TField NAME_FIELD_DESC = new TField("name", TType.STRING, (short)1);
    private static final TField STORAGE_FIELD_DESC = new TField("storage", TType.STRING, (short)2);
    private static final TField THRIFT_PORT_FIELD_DESC = new TField("thriftPort", TType.I32, (short)3);

    /**
     * <host name>:<port number> of the datanode
     */
    public String name;
    /**
     * the storage id of the datanode
     */
    public String storage;
    /**
     * Thrift port of the datanode
     */
    public int thriftPort;

    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
      /**
       * <host name>:<port number> of the datanode
       */
      NAME((short)1, "name"),
      /**
       * the storage id of the datanode
       */
      STORAGE((short)2, "storage"),
      /**
       * Thrift port of the datanode
       */
      THRIFT_PORT((short)3, "thriftPort");

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }

    // isset id assignments
    private static final int __THRIFTPORT_ISSET_ID = 0;
    private BitSet __isset_bit_vector = new BitSet(1);

    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
      put(_Fields.NAME, new FieldMetaData("name", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.STORAGE, new FieldMetaData("storage", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.STRING)));
      put(_Fields.THRIFT_PORT, new FieldMetaData("thriftPort", TFieldRequirementType.DEFAULT, 
          new FieldValueMetaData(TType.I32)));
    }});

    static {
      FieldMetaData.addStructMetaDataMap(datanodeDown_args.class, metaDataMap);
    }

    public datanodeDown_args() {
    }

    public datanodeDown_args(
      String name,
      String storage,
      int thriftPort)
    {
      this();
      this.name = name;
      this.storage = storage;
      this.thriftPort = thriftPort;
      setThriftPortIsSet(true);
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public datanodeDown_args(datanodeDown_args other) {
      __isset_bit_vector.clear();
      __isset_bit_vector.or(other.__isset_bit_vector);
      if (other.isSetName()) {
        this.name = other.name;
      }
      if (other.isSetStorage()) {
        this.storage = other.storage;
      }
      this.thriftPort = other.thriftPort;
    }

    public datanodeDown_args deepCopy() {
      return new datanodeDown_args(this);
    }

    @Deprecated
    public datanodeDown_args clone() {
      return new datanodeDown_args(this);
    }

    /**
     * <host name>:<port number> of the datanode
     */
    public String getName() {
      return this.name;
    }

    /**
     * <host name>:<port number> of the datanode
     */
    public datanodeDown_args setName(String name) {
      this.name = name;
      return this;
    }

    public void unsetName() {
      this.name = null;
    }

    /** Returns true if field name is set (has been asigned a value) and false otherwise */
    public boolean isSetName() {
      return this.name != null;
    }

    public void setNameIsSet(boolean value) {
      if (!value) {
        this.name = null;
      }
    }

    /**
     * the storage id of the datanode
     */
    public String getStorage() {
      return this.storage;
    }

    /**
     * the storage id of the datanode
     */
    public datanodeDown_args setStorage(String storage) {
      this.storage = storage;
      return this;
    }

    public void unsetStorage() {
      this.storage = null;
    }

    /** Returns true if field storage is set (has been asigned a value) and false otherwise */
    public boolean isSetStorage() {
      return this.storage != null;
    }

    public void setStorageIsSet(boolean value) {
      if (!value) {
        this.storage = null;
      }
    }

    /**
     * Thrift port of the datanode
     */
    public int getThriftPort() {
      return this.thriftPort;
    }

    /**
     * Thrift port of the datanode
     */
    public datanodeDown_args setThriftPort(int thriftPort) {
      this.thriftPort = thriftPort;
      setThriftPortIsSet(true);
      return this;
    }

    public void unsetThriftPort() {
      __isset_bit_vector.clear(__THRIFTPORT_ISSET_ID);
    }

    /** Returns true if field thriftPort is set (has been asigned a value) and false otherwise */
    public boolean isSetThriftPort() {
      return __isset_bit_vector.get(__THRIFTPORT_ISSET_ID);
    }

    public void setThriftPortIsSet(boolean value) {
      __isset_bit_vector.set(__THRIFTPORT_ISSET_ID, value);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      case NAME:
        if (value == null) {
          unsetName();
        } else {
          setName((String)value);
        }
        break;

      case STORAGE:
        if (value == null) {
          unsetStorage();
        } else {
          setStorage((String)value);
        }
        break;

      case THRIFT_PORT:
        if (value == null) {
          unsetThriftPort();
        } else {
          setThriftPort((Integer)value);
        }
        break;

      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      case NAME:
        return getName();

      case STORAGE:
        return getStorage();

      case THRIFT_PORT:
        return new Integer(getThriftPort());

      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      case NAME:
        return isSetName();
      case STORAGE:
        return isSetStorage();
      case THRIFT_PORT:
        return isSetThriftPort();
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof datanodeDown_args)
        return this.equals((datanodeDown_args)that);
      return false;
    }

    public boolean equals(datanodeDown_args that) {
      if (that == null)
        return false;

      boolean this_present_name = true && this.isSetName();
      boolean that_present_name = true && that.isSetName();
      if (this_present_name || that_present_name) {
        if (!(this_present_name && that_present_name))
          return false;
        if (!this.name.equals(that.name))
          return false;
      }

      boolean this_present_storage = true && this.isSetStorage();
      boolean that_present_storage = true && that.isSetStorage();
      if (this_present_storage || that_present_storage) {
        if (!(this_present_storage && that_present_storage))
          return false;
        if (!this.storage.equals(that.storage))
          return false;
      }

      boolean this_present_thriftPort = true;
      boolean that_present_thriftPort = true;
      if (this_present_thriftPort || that_present_thriftPort) {
        if (!(this_present_thriftPort && that_present_thriftPort))
          return false;
        if (this.thriftPort != that.thriftPort)
          return false;
      }

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(datanodeDown_args other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      datanodeDown_args typedOther = (datanodeDown_args)other;

      lastComparison = Boolean.valueOf(isSetName()).compareTo(isSetName());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(name, typedOther.name);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetStorage()).compareTo(isSetStorage());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(storage, typedOther.storage);
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = Boolean.valueOf(isSetThriftPort()).compareTo(isSetThriftPort());
      if (lastComparison != 0) {
        return lastComparison;
      }
      lastComparison = TBaseHelper.compareTo(thriftPort, typedOther.thriftPort);
      if (lastComparison != 0) {
        return lastComparison;
      }
      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
            case NAME:
              if (field.type == TType.STRING) {
                this.name = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case STORAGE:
              if (field.type == TType.STRING) {
                this.storage = iprot.readString();
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
            case THRIFT_PORT:
              if (field.type == TType.I32) {
                this.thriftPort = iprot.readI32();
                setThriftPortIsSet(true);
              } else { 
                TProtocolUtil.skip(iprot, field.type);
              }
              break;
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      validate();

      oprot.writeStructBegin(STRUCT_DESC);
      if (this.name != null) {
        oprot.writeFieldBegin(NAME_FIELD_DESC);
        oprot.writeString(this.name);
        oprot.writeFieldEnd();
      }
      if (this.storage != null) {
        oprot.writeFieldBegin(STORAGE_FIELD_DESC);
        oprot.writeString(this.storage);
        oprot.writeFieldEnd();
      }
      oprot.writeFieldBegin(THRIFT_PORT_FIELD_DESC);
      oprot.writeI32(this.thriftPort);
      oprot.writeFieldEnd();
      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("datanodeDown_args(");
      boolean first = true;

      sb.append("name:");
      if (this.name == null) {
        sb.append("null");
      } else {
        sb.append(this.name);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("storage:");
      if (this.storage == null) {
        sb.append("null");
      } else {
        sb.append(this.storage);
      }
      first = false;
      if (!first) sb.append(", ");
      sb.append("thriftPort:");
      sb.append(this.thriftPort);
      first = false;
      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

  public static class datanodeDown_result implements TBase<datanodeDown_result._Fields>, java.io.Serializable, Cloneable, Comparable<datanodeDown_result>   {
    private static final TStruct STRUCT_DESC = new TStruct("datanodeDown_result");



    /** The set of fields this struct contains, along with convenience methods for finding and manipulating them. */
    public enum _Fields implements TFieldIdEnum {
;

      private static final Map<Integer, _Fields> byId = new HashMap<Integer, _Fields>();
      private static final Map<String, _Fields> byName = new HashMap<String, _Fields>();

      static {
        for (_Fields field : EnumSet.allOf(_Fields.class)) {
          byId.put((int)field._thriftId, field);
          byName.put(field.getFieldName(), field);
        }
      }

      /**
       * Find the _Fields constant that matches fieldId, or null if its not found.
       */
      public static _Fields findByThriftId(int fieldId) {
        return byId.get(fieldId);
      }

      /**
       * Find the _Fields constant that matches fieldId, throwing an exception
       * if it is not found.
       */
      public static _Fields findByThriftIdOrThrow(int fieldId) {
        _Fields fields = findByThriftId(fieldId);
        if (fields == null) throw new IllegalArgumentException("Field " + fieldId + " doesn't exist!");
        return fields;
      }

      /**
       * Find the _Fields constant that matches name, or null if its not found.
       */
      public static _Fields findByName(String name) {
        return byName.get(name);
      }

      private final short _thriftId;
      private final String _fieldName;

      _Fields(short thriftId, String fieldName) {
        _thriftId = thriftId;
        _fieldName = fieldName;
      }

      public short getThriftFieldId() {
        return _thriftId;
      }

      public String getFieldName() {
        return _fieldName;
      }
    }
    public static final Map<_Fields, FieldMetaData> metaDataMap = Collections.unmodifiableMap(new EnumMap<_Fields, FieldMetaData>(_Fields.class) {{
    }});

    static {
      FieldMetaData.addStructMetaDataMap(datanodeDown_result.class, metaDataMap);
    }

    public datanodeDown_result() {
    }

    /**
     * Performs a deep copy on <i>other</i>.
     */
    public datanodeDown_result(datanodeDown_result other) {
    }

    public datanodeDown_result deepCopy() {
      return new datanodeDown_result(this);
    }

    @Deprecated
    public datanodeDown_result clone() {
      return new datanodeDown_result(this);
    }

    public void setFieldValue(_Fields field, Object value) {
      switch (field) {
      }
    }

    public void setFieldValue(int fieldID, Object value) {
      setFieldValue(_Fields.findByThriftIdOrThrow(fieldID), value);
    }

    public Object getFieldValue(_Fields field) {
      switch (field) {
      }
      throw new IllegalStateException();
    }

    public Object getFieldValue(int fieldId) {
      return getFieldValue(_Fields.findByThriftIdOrThrow(fieldId));
    }

    /** Returns true if field corresponding to fieldID is set (has been asigned a value) and false otherwise */
    public boolean isSet(_Fields field) {
      switch (field) {
      }
      throw new IllegalStateException();
    }

    public boolean isSet(int fieldID) {
      return isSet(_Fields.findByThriftIdOrThrow(fieldID));
    }

    @Override
    public boolean equals(Object that) {
      if (that == null)
        return false;
      if (that instanceof datanodeDown_result)
        return this.equals((datanodeDown_result)that);
      return false;
    }

    public boolean equals(datanodeDown_result that) {
      if (that == null)
        return false;

      return true;
    }

    @Override
    public int hashCode() {
      return 0;
    }

    public int compareTo(datanodeDown_result other) {
      if (!getClass().equals(other.getClass())) {
        return getClass().getName().compareTo(other.getClass().getName());
      }

      int lastComparison = 0;
      datanodeDown_result typedOther = (datanodeDown_result)other;

      return 0;
    }

    public void read(TProtocol iprot) throws TException {
      TField field;
      iprot.readStructBegin();
      while (true)
      {
        field = iprot.readFieldBegin();
        if (field.type == TType.STOP) { 
          break;
        }
        _Fields fieldId = _Fields.findByThriftId(field.id);
        if (fieldId == null) {
          TProtocolUtil.skip(iprot, field.type);
        } else {
          switch (fieldId) {
          }
          iprot.readFieldEnd();
        }
      }
      iprot.readStructEnd();

      // check for required fields of primitive type, which can't be checked in the validate method
      validate();
    }

    public void write(TProtocol oprot) throws TException {
      oprot.writeStructBegin(STRUCT_DESC);

      oprot.writeFieldStop();
      oprot.writeStructEnd();
    }

    @Override
    public String toString() {
      StringBuilder sb = new StringBuilder("datanodeDown_result(");
      boolean first = true;

      sb.append(")");
      return sb.toString();
    }

    public void validate() throws TException {
      // check for required fields
    }

  }

}
